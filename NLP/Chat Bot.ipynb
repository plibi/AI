{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGeV53DoJmLB"
   },
   "source": [
    "# 챗봇\n",
    "\n",
    "1. 데이터 분석\n",
    "    - \n",
    "2. 데이터 전처리\n",
    "3. 모델링\n",
    "    - 모델 평가 어떻게?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bc_0_3BqJ2c6"
   },
   "source": [
    "## 1. 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMWHMsFCJnuW"
   },
   "source": [
    "### Sentence piece를 이용해 subword로 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "WR8EReF8H53D",
    "outputId": "83ff155c-dbc3-4259-db91-40a82e4be2b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |▎                               | 10 kB 23.4 MB/s eta 0:00:01\r",
      "\u001b[K     |▌                               | 20 kB 30.1 MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 30 kB 17.0 MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 40 kB 11.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█▍                              | 51 kB 6.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 61 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 71 kB 7.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 81 kB 7.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 92 kB 7.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 102 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 112 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 122 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 133 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 143 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 153 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 163 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 174 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 184 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 194 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 204 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 215 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 225 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 235 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 245 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 256 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 266 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 276 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 286 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 296 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 307 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 317 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 327 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 337 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 348 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 358 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 368 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 378 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 389 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 399 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 409 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 419 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 430 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 440 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 450 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 460 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 471 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 481 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 491 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 501 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 512 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 522 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 532 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 542 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 552 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 563 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 573 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 583 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 593 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 604 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 614 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 624 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 634 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 645 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 655 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 665 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 675 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 686 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 696 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 706 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 716 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 727 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 737 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 747 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 757 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 768 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 778 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 788 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 798 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 808 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 819 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 829 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 839 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 849 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 860 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 870 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 880 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 890 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 901 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 911 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 921 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 931 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 942 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 952 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 962 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 972 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 983 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 993 kB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 1.0 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 1.0 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.0 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 1.0 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 1.0 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 1.1 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 1.1 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 1.1 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 1.1 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 1.1 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 1.1 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 1.1 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 1.1 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.1 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 1.1 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 1.2 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 1.2 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 1.2 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 1.2 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 1.2 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 1.2 MB 6.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.2 MB 6.9 MB/s \n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.96\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "DtF4afUOH8mw",
    "outputId": "a61692b1-7e23-4daf-d5fa-9f397c27d797"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "# 작업 디렉토리를 변경한다.\n",
    "%cd '/content/drive/My Drive/Colab Notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ERVSZ--gV3Vy",
    "outputId": "8d4c9fd9-bc7d-4c0b-bbf5-db0e01664ab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "d7KMb1-VI0yT"
   },
   "outputs": [],
   "source": [
    "# Seq2Seq ChatBot : 학습 데이터 모듈\n",
    "# Google의 Sentencepiece를 이용해서 학습 데이터를 생성한다.\n",
    "#\n",
    "# 저작자: 2021.05.26, 조성현 (blog.naver.com/chunjein)\n",
    "# copyright: SNS 등에 공개할 때는 출처에 저작자를 명시해 주시기 바랍니다.\n",
    "# -----------------------------------------------------------------------\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8dexVvt2I12s",
    "outputId": "7b90011b-830f-410c-b211-c59e891b94bb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-55108036-2f17-45c1-a2a6-94b824773033\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55108036-2f17-45c1-a2a6-94b824773033')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-55108036-2f17-45c1-a2a6-94b824773033 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-55108036-2f17-45c1-a2a6-94b824773033');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 파일을 읽어온다.\n",
    "data_df = pd.read_csv('data/ChatBotData.csv', header=0)\n",
    "question, answer = list(data_df['Q']), list(data_df['A'])\n",
    "\n",
    "# 특수 문자를 제거한다.\n",
    "FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "question = [re.sub(FILTERS, \"\", s) for s in question]\n",
    "answer = [re.sub(FILTERS, \"\", s) for s in answer]\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "tNgnK1oGJaKg",
    "outputId": "2502e149-1656-4a04-de79-63c72098ce7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('가스비 너무 많이 나왔다', '다음 달에는 더 절약해봐요')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 학습 데이터와 시험 데이터를 분리한다.\n",
    "# que_train, que_test, ans_train, ans_test = train_test_split(question, answer, test_size=0.1, random_state=0)\n",
    "\n",
    "# que_train[0], ans_train[0]\n",
    "\n",
    "i = 19\n",
    "question[i], answer[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Dt90Pze7JdwE"
   },
   "outputs": [],
   "source": [
    "# Sentencepice용 사전을 만들기 위해 que_train + que_test를 저장해 둔다.\n",
    "data_file = \"data/chatbot_data.txt\"\n",
    "with open(data_file, 'w', encoding='utf-8') as f:\n",
    "    for sent in question + answer:\n",
    "        f.write(sent + '\\n')\n",
    "        \n",
    "# Google의 Sentencepiece를 이용해서 vocabulary를 생성한다.\n",
    "# -----------------------------------------------------\n",
    "templates= \"--input={} \\\n",
    "            --pad_id=0 --pad_piece=<PAD>\\\n",
    "            --unk_id=1 --unk_piece=<UNK>\\\n",
    "            --bos_id=2 --bos_piece=<BOS>\\\n",
    "            --eos_id=3 --eos_piece=<EOS>\\\n",
    "            --model_prefix={} \\\n",
    "            --vocab_size={}\"\n",
    "\n",
    "VOCAB_SIZE = 9000\n",
    "model_prefix = \"data/chatbot_model\"\n",
    "params = templates.format(data_file, model_prefix, VOCAB_SIZE)\n",
    "\n",
    "spm.SentencePieceTrainer.Train(params)\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(model_prefix + '.model')\n",
    "\n",
    "with open(model_prefix + '.vocab', encoding='utf-8') as f:\n",
    "    vocab = [doc.strip().split('\\t') for doc in f]\n",
    "\n",
    "word2idx = {k:v for v, [k, _] in enumerate(vocab)}\n",
    "idx2word = {v:k for v, [k, _] in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "bIKZCvOiJ8o2",
    "outputId": "4468ea85-0698-4786-bc67-3818e0e5ffd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<UNK>': 1,\n",
       " '<BOS>': 2,\n",
       " '<EOS>': 3,\n",
       " '▁': 4,\n",
       " '을': 5,\n",
       " '가': 6,\n",
       " '도': 7,\n",
       " '요': 8,\n",
       " '이': 9,\n",
       " '는': 10,\n",
       " '게': 11,\n",
       " '▁거예요': 12,\n",
       " '은': 13,\n",
       " '세요': 14,\n",
       " '고': 15,\n",
       " '지': 16,\n",
       " '를': 17,\n",
       " '▁수': 18,\n",
       " '의': 19,\n",
       " '▁너무': 20,\n",
       " '죠': 21,\n",
       " '보세요': 22,\n",
       " '▁거': 23,\n",
       " '▁좋아하는': 24,\n",
       " '▁더': 25,\n",
       " '▁사람': 26,\n",
       " '▁것': 27,\n",
       " '▁잘': 28,\n",
       " '▁안': 29,\n",
       " '서': 30,\n",
       " '▁나': 31,\n",
       " '한': 32,\n",
       " '에': 33,\n",
       " '면': 34,\n",
       " '▁사랑': 35,\n",
       " '네요': 36,\n",
       " '▁많이': 37,\n",
       " '▁좋은': 38,\n",
       " '히': 39,\n",
       " '▁그': 40,\n",
       " '▁좀': 41,\n",
       " '▁싶어': 42,\n",
       " '만': 43,\n",
       " '▁같아요': 44,\n",
       " '▁이별': 45,\n",
       " '랑': 46,\n",
       " '▁있어요': 47,\n",
       " '▁있을': 48,\n",
       " '▁사람이': 49,\n",
       " '으로': 50,\n",
       " '▁게': 51,\n",
       " '▁마음': 52,\n",
       " '로': 53,\n",
       " '네': 54,\n",
       " '▁때': 55,\n",
       " '▁썸': 56,\n",
       " '▁같아': 57,\n",
       " '▁내': 58,\n",
       " '▁생각': 59,\n",
       " '어': 60,\n",
       " '다': 61,\n",
       " '해보세요': 62,\n",
       " '▁다': 63,\n",
       " '나': 64,\n",
       " '하고': 65,\n",
       " '▁마세요': 66,\n",
       " '길': 67,\n",
       " '▁건': 68,\n",
       " '하세요': 69,\n",
       " '▁말': 70,\n",
       " '▁이제': 71,\n",
       " '▁오늘': 72,\n",
       " '할': 73,\n",
       " '나봐요': 74,\n",
       " '▁있': 75,\n",
       " '▁좋': 76,\n",
       " '▁마음이': 77,\n",
       " '▁내가': 78,\n",
       " '▁있는': 79,\n",
       " '▁왜': 80,\n",
       " '에서': 81,\n",
       " '야': 82,\n",
       " '▁해보세요': 83,\n",
       " '▁다른': 84,\n",
       " '▁어떻게': 85,\n",
       " '겠네요': 86,\n",
       " '겠어요': 87,\n",
       " '▁남자친구': 88,\n",
       " '▁뭐': 89,\n",
       " '▁가': 90,\n",
       " '니다': 91,\n",
       " '▁시간이': 92,\n",
       " '▁싶다': 93,\n",
       " '▁다시': 94,\n",
       " '▁여자친구': 95,\n",
       " '▁없어': 96,\n",
       " '▁일': 97,\n",
       " '일': 98,\n",
       " '▁정말': 99,\n",
       " '▁또': 100,\n",
       " '▁저': 101,\n",
       " '▁있어': 102,\n",
       " '▁연애': 103,\n",
       " '▁해': 104,\n",
       " '▁한': 105,\n",
       " '주세요': 106,\n",
       " '이에요': 107,\n",
       " '하는': 108,\n",
       " '▁좋을': 109,\n",
       " '▁연락': 110,\n",
       " '▁걸': 111,\n",
       " '▁수도': 112,\n",
       " '▁친구': 113,\n",
       " '▁못': 114,\n",
       " '▁하는': 115,\n",
       " '▁조금': 116,\n",
       " '▁같이': 117,\n",
       " '해': 118,\n",
       " '▁자신': 119,\n",
       " '는데': 120,\n",
       " '▁좋아': 121,\n",
       " '▁여자': 122,\n",
       " '▁될': 123,\n",
       " '▁지금': 124,\n",
       " '▁하고': 125,\n",
       " '것도': 126,\n",
       " '▁사': 127,\n",
       " '▁혼자': 128,\n",
       " '습니다': 129,\n",
       " '▁할': 130,\n",
       " '으면': 131,\n",
       " '▁힘들': 132,\n",
       " '▁바': 133,\n",
       " '▁자꾸': 134,\n",
       " '겠죠': 135,\n",
       " '▁당신': 136,\n",
       " '▁시간': 137,\n",
       " '하지': 138,\n",
       " '인데': 139,\n",
       " '기': 140,\n",
       " '년': 141,\n",
       " '▁없어요': 142,\n",
       " '▁드': 143,\n",
       " '든': 144,\n",
       " '▁이': 145,\n",
       " '거': 146,\n",
       " '▁바랄게요': 147,\n",
       " '▁진짜': 148,\n",
       " '▁그런': 149,\n",
       " '▁일이': 150,\n",
       " '▁살': 151,\n",
       " '▁먼저': 152,\n",
       " '▁돼요': 153,\n",
       " '▁될까': 154,\n",
       " '▁제가': 155,\n",
       " '과': 156,\n",
       " '▁헤어진지': 157,\n",
       " '합니다': 158,\n",
       " '▁만나': 159,\n",
       " '▁저도': 160,\n",
       " '하게': 161,\n",
       " '▁아무': 162,\n",
       " '▁있을까': 163,\n",
       " '▁없는': 164,\n",
       " '▁하나': 165,\n",
       " '한테': 166,\n",
       " '▁선물': 167,\n",
       " '는게': 168,\n",
       " '▁계속': 169,\n",
       " '▁남자': 170,\n",
       " '▁좋겠어': 171,\n",
       " '거예요': 172,\n",
       " '라': 173,\n",
       " '▁힘든': 174,\n",
       " '▁좋아요': 175,\n",
       " '▁그럴': 176,\n",
       " '인': 177,\n",
       " '까': 178,\n",
       " '봅니다': 179,\n",
       " '▁하': 180,\n",
       " '어요': 181,\n",
       " '랍': 182,\n",
       " '▁먹고': 183,\n",
       " '▁짝녀': 184,\n",
       " '▁않': 185,\n",
       " '▁서로': 186,\n",
       " '데': 187,\n",
       " '▁전': 188,\n",
       " '▁않아요': 189,\n",
       " '▁방법': 190,\n",
       " '▁사랑이': 191,\n",
       " '보다': 192,\n",
       " '▁술': 193,\n",
       " '가봐요': 194,\n",
       " '라고': 195,\n",
       " '▁참': 196,\n",
       " '하면': 197,\n",
       " '운': 198,\n",
       " '▁없': 199,\n",
       " '▁날': 200,\n",
       " '▁중': 201,\n",
       " '입니다': 202,\n",
       " '▁짝사랑': 203,\n",
       " '▁아직': 204,\n",
       " '던': 205,\n",
       " '봐요': 206,\n",
       " '▁이야기': 207,\n",
       " '씩': 208,\n",
       " '▁눈': 209,\n",
       " '상': 210,\n",
       " '▁결혼': 211,\n",
       " '▁준비': 212,\n",
       " '다고': 213,\n",
       " '▁애': 214,\n",
       " '니까요': 215,\n",
       " '니': 216,\n",
       " '▁많은': 217,\n",
       " '▁하지': 218,\n",
       " '▁말해보세요': 219,\n",
       " '▁생각해요': 220,\n",
       " '▁데이트': 221,\n",
       " '▁보고': 222,\n",
       " '▁충분': 223,\n",
       " '▁고민': 224,\n",
       " '해도': 225,\n",
       " '▁무슨': 226,\n",
       " '▁줄': 227,\n",
       " '▁해요': 228,\n",
       " '▁그냥': 229,\n",
       " '▁짝남이': 230,\n",
       " '▁이렇게': 231,\n",
       " '▁돈': 232,\n",
       " '▁어떤': 233,\n",
       " '까지': 234,\n",
       " '했어': 235,\n",
       " '▁그렇': 236,\n",
       " '▁할까': 237,\n",
       " '에게': 238,\n",
       " '지만': 239,\n",
       " '지도': 240,\n",
       " '▁몰라요': 241,\n",
       " '▁나만': 242,\n",
       " '▁친구가': 243,\n",
       " '▁대화': 244,\n",
       " '▁안돼': 245,\n",
       " '예요': 246,\n",
       " '▁사람은': 247,\n",
       " '▁힘드네': 248,\n",
       " '래': 249,\n",
       " '▁들어': 250,\n",
       " '▁1': 251,\n",
       " '▁싫어': 252,\n",
       " '▁2': 253,\n",
       " '해요': 254,\n",
       " '대로': 255,\n",
       " '▁함께': 256,\n",
       " '▁아': 257,\n",
       " '▁머리': 258,\n",
       " '▁하루': 259,\n",
       " '▁오래': 260,\n",
       " '할까': 261,\n",
       " '▁내일': 262,\n",
       " '▁공부': 263,\n",
       " '▁짝남': 264,\n",
       " '▁관심': 265,\n",
       " '나를': 266,\n",
       " '▁너': 267,\n",
       " '▁새로운': 268,\n",
       " '려': 269,\n",
       " '▁카톡': 270,\n",
       " '▁바라': 271,\n",
       " '▁남': 272,\n",
       " '▁보세요': 273,\n",
       " '▁힘들어': 274,\n",
       " '▁어떨까요': 275,\n",
       " '▁되': 276,\n",
       " '와': 277,\n",
       " '▁알': 278,\n",
       " '▁헤어진': 279,\n",
       " '▁있는데': 280,\n",
       " '▁같': 281,\n",
       " '▁사랑하는': 282,\n",
       " '▁생각해보세요': 283,\n",
       " '▁여행': 284,\n",
       " '▁후': 285,\n",
       " '▁해야': 286,\n",
       " '▁듯': 287,\n",
       " '▁그래': 288,\n",
       " '▁감정': 289,\n",
       " '▁하면': 290,\n",
       " '▁3': 291,\n",
       " '대': 292,\n",
       " '군': 293,\n",
       " '게요': 294,\n",
       " '▁연락이': 295,\n",
       " '▁타는': 296,\n",
       " '▁누구': 297,\n",
       " '▁보': 298,\n",
       " '▁돼': 299,\n",
       " '▁아니에요': 300,\n",
       " '이네요': 301,\n",
       " '▁말고': 302,\n",
       " '▁이유': 303,\n",
       " '▁생각이': 304,\n",
       " '른': 305,\n",
       " '심': 306,\n",
       " '항': 307,\n",
       " '▁않아': 308,\n",
       " '▁고백': 309,\n",
       " '▁싶은': 310,\n",
       " '▁열': 311,\n",
       " '진': 312,\n",
       " '▁이젠': 313,\n",
       " '▁많아': 314,\n",
       " '▁해도': 315,\n",
       " '▁마음에': 316,\n",
       " '하죠': 317,\n",
       " '▁끝': 318,\n",
       " '▁올': 319,\n",
       " '▁따라': 320,\n",
       " '▁스트레스': 321,\n",
       " '겠지': 322,\n",
       " '▁않는': 323,\n",
       " '▁나한테': 324,\n",
       " '▁같은데': 325,\n",
       " '▁도움': 326,\n",
       " '부터': 327,\n",
       " '▁운동': 328,\n",
       " '▁만큼': 329,\n",
       " '▁만날': 330,\n",
       " '볼까': 331,\n",
       " '▁가고': 332,\n",
       " '▁기억': 333,\n",
       " '▁우리': 334,\n",
       " '▁쉽지': 335,\n",
       " '▁곳': 336,\n",
       " '자': 337,\n",
       " '▁후회': 338,\n",
       " '이야': 339,\n",
       " '▁좋겠다': 340,\n",
       " '▁쉬': 341,\n",
       " '해주세요': 342,\n",
       " '▁그녀': 343,\n",
       " '해서': 344,\n",
       " '▁정리': 345,\n",
       " '▁맘': 346,\n",
       " '▁제': 347,\n",
       " '▁모르겠어': 348,\n",
       " '▁오': 349,\n",
       " '해볼까': 350,\n",
       " '수': 351,\n",
       " '▁기분': 352,\n",
       " '▁꿈': 353,\n",
       " '자고': 354,\n",
       " '▁어때': 355,\n",
       " '인지': 356,\n",
       " '질': 357,\n",
       " '시': 358,\n",
       " '애': 359,\n",
       " '▁이별을': 360,\n",
       " '▁않을': 361,\n",
       " '건': 362,\n",
       " '▁같은': 363,\n",
       " '거라': 364,\n",
       " '▁집': 365,\n",
       " '▁직접': 366,\n",
       " '▁시작': 367,\n",
       " '▁얼': 368,\n",
       " '▁언제': 369,\n",
       " '▁좋을까': 370,\n",
       " '▁꼭': 371,\n",
       " '리': 372,\n",
       " '▁전화': 373,\n",
       " '▁문제': 374,\n",
       " '▁자': 375,\n",
       " '▁아니': 376,\n",
       " '▁생각해': 377,\n",
       " '▁있나': 378,\n",
       " '▁걱정': 379,\n",
       " '▁볼': 380,\n",
       " '면서': 381,\n",
       " '▁괜찮아요': 382,\n",
       " '거나': 383,\n",
       " '아': 384,\n",
       " '▁어디': 385,\n",
       " '▁요즘': 386,\n",
       " '▁변화': 387,\n",
       " '▁반': 388,\n",
       " '니까': 389,\n",
       " '▁점': 390,\n",
       " '▁결국': 391,\n",
       " '구': 392,\n",
       " '▁기대': 393,\n",
       " '▁찾아': 394,\n",
       " '▁되는': 395,\n",
       " '▁비': 396,\n",
       " '걸': 397,\n",
       " '점': 398,\n",
       " '▁피': 399,\n",
       " '▁알아': 400,\n",
       " '▁나는': 401,\n",
       " '긴': 402,\n",
       " '▁않은': 403,\n",
       " '▁맛있': 404,\n",
       " '▁와': 405,\n",
       " '▁있죠': 406,\n",
       " '함': 407,\n",
       " '다면': 408,\n",
       " '▁아니라': 409,\n",
       " '▁가는': 410,\n",
       " '만큼': 411,\n",
       " '▁아직도': 412,\n",
       " '▁말아요': 413,\n",
       " '▁집에': 414,\n",
       " '▁한달': 415,\n",
       " '▁중요한': 416,\n",
       " '▁싶은데': 417,\n",
       " '▁마음의': 418,\n",
       " '▁늦': 419,\n",
       " '려고': 420,\n",
       " '간': 421,\n",
       " '▁물어보': 422,\n",
       " '기도': 423,\n",
       " '적인': 424,\n",
       " '▁어제': 425,\n",
       " '▁연락을': 426,\n",
       " '▁노래': 427,\n",
       " '▁때문에': 428,\n",
       " '야지': 429,\n",
       " '▁연락해보세요': 430,\n",
       " '▁인생': 431,\n",
       " '인가봐요': 432,\n",
       " '▁모르는': 433,\n",
       " '대한': 434,\n",
       " '▁갑': 435,\n",
       " '▁회사': 436,\n",
       " '▁필요해': 437,\n",
       " '▁필요': 438,\n",
       " '수록': 439,\n",
       " '▁아파': 440,\n",
       " '▁매일': 441,\n",
       " '처럼': 442,\n",
       " '▁상처': 443,\n",
       " '▁시간을': 444,\n",
       " '▁거라': 445,\n",
       " '▁큰': 446,\n",
       " '▁완전': 447,\n",
       " '▁가장': 448,\n",
       " '▁싶': 449,\n",
       " '자기': 450,\n",
       " '▁오늘도': 451,\n",
       " '▁마지막': 452,\n",
       " '이라': 453,\n",
       " '▁있나봐요': 454,\n",
       " '여': 455,\n",
       " '들': 456,\n",
       " '▁맞는': 457,\n",
       " '장': 458,\n",
       " '오세요': 459,\n",
       " '임': 460,\n",
       " '▁잠': 461,\n",
       " '▁관계': 462,\n",
       " '▁현실': 463,\n",
       " '주': 464,\n",
       " '제일': 465,\n",
       " '▁보내': 466,\n",
       " '▁남자애': 467,\n",
       " '▁나쁜': 468,\n",
       " '▁여친': 469,\n",
       " '▁딱': 470,\n",
       " '▁타': 471,\n",
       " '▁헤어짐': 472,\n",
       " '천': 473,\n",
       " '이죠': 474,\n",
       " '▁이런': 475,\n",
       " '에요': 476,\n",
       " '걸까': 477,\n",
       " '▁살고': 478,\n",
       " '▁핸드폰': 479,\n",
       " '▁용기': 480,\n",
       " '▁모든': 481,\n",
       " '▁고민이': 482,\n",
       " '▁가지': 483,\n",
       " '▁헤어지고': 484,\n",
       " '개월': 485,\n",
       " '▁몸': 486,\n",
       " '▁얼마': 487,\n",
       " '▁잘할': 488,\n",
       " '▁미련': 489,\n",
       " '▁남자가': 490,\n",
       " '돼': 491,\n",
       " '▁밥': 492,\n",
       " '▁어느': 493,\n",
       " '▁뭘': 494,\n",
       " '▁나이': 495,\n",
       " '▁중요해요': 496,\n",
       " '▁만들어': 497,\n",
       " '하네': 498,\n",
       " '때': 499,\n",
       " '음': 500,\n",
       " '▁난': 501,\n",
       " '하는데': 502,\n",
       " '▁입': 503,\n",
       " '▁기': 504,\n",
       " '▁정': 505,\n",
       " '▁차': 506,\n",
       " '러': 507,\n",
       " '▁알았는데': 508,\n",
       " '▁뭘까': 509,\n",
       " '▁확신': 510,\n",
       " '▁사진': 511,\n",
       " '▁마': 512,\n",
       " '▁천': 513,\n",
       " '▁없다': 514,\n",
       " '에는': 515,\n",
       " '▁덜': 516,\n",
       " '▁잘하는': 517,\n",
       " '▁사람들이': 518,\n",
       " '이랑': 519,\n",
       " '▁기다려': 520,\n",
       " '▁아침': 521,\n",
       " '▁가끔': 522,\n",
       " '▁스스로': 523,\n",
       " '방': 524,\n",
       " '▁예의': 525,\n",
       " '▁왔어': 526,\n",
       " '▁썸남': 527,\n",
       " '▁상대방': 528,\n",
       " '▁자기': 529,\n",
       " '차': 530,\n",
       " '▁했는데': 531,\n",
       " '▁없네': 532,\n",
       " '▁번': 533,\n",
       " '▁사랑에': 534,\n",
       " '▁재회': 535,\n",
       " '▁남친': 536,\n",
       " '▁엄청': 537,\n",
       " '▁되나': 538,\n",
       " '▁물': 539,\n",
       " '▁아닌': 540,\n",
       " '▁자주': 541,\n",
       " '▁커피': 542,\n",
       " '▁날씨': 543,\n",
       " '▁모두': 544,\n",
       " '▁많았': 545,\n",
       " '▁어떡해': 546,\n",
       " '▁짝남한테': 547,\n",
       " '▁인연이': 548,\n",
       " '▁놀': 549,\n",
       " '▁조심하': 550,\n",
       " '▁보는': 551,\n",
       " '▁들': 552,\n",
       " '▁길': 553,\n",
       " '▁선택': 554,\n",
       " '일까': 555,\n",
       " '▁만나는': 556,\n",
       " '▁정리가': 557,\n",
       " '▁기분이': 558,\n",
       " '▁당신이': 559,\n",
       " '▁엄마': 560,\n",
       " '▁5': 561,\n",
       " '▁그만': 562,\n",
       " '▁새': 563,\n",
       " '▁한번': 564,\n",
       " '▁소개팅': 565,\n",
       " '▁된': 566,\n",
       " '하': 567,\n",
       " '▁쉬운': 568,\n",
       " '▁사람한테': 569,\n",
       " '▁받아': 570,\n",
       " '▁처음': 571,\n",
       " '▁없을': 572,\n",
       " '▁결정': 573,\n",
       " '▁화': 574,\n",
       " '▁대': 575,\n",
       " '▁갈': 576,\n",
       " '하기': 577,\n",
       " '▁필요한': 578,\n",
       " '▁진심': 579,\n",
       " '▁의미': 580,\n",
       " '했던': 581,\n",
       " '▁기다리': 582,\n",
       " '하면서': 583,\n",
       " '▁있다면': 584,\n",
       " '인가': 585,\n",
       " '▁사는': 586,\n",
       " '정': 587,\n",
       " '▁추천': 588,\n",
       " '된': 589,\n",
       " '져': 590,\n",
       " '▁좋아할': 591,\n",
       " '▁모르겠어요': 592,\n",
       " '마다': 593,\n",
       " '▁연습': 594,\n",
       " '▁영화': 595,\n",
       " '이나': 596,\n",
       " '적': 597,\n",
       " '▁후폭풍': 598,\n",
       " '▁상대': 599,\n",
       " '▁느낌': 600,\n",
       " '마세요': 601,\n",
       " '▁손': 602,\n",
       " '▁몇': 603,\n",
       " '▁앞에': 604,\n",
       " '더니': 605,\n",
       " '▁정도': 606,\n",
       " '▁행복': 607,\n",
       " '▁나와': 608,\n",
       " '▁좋아하': 609,\n",
       " '▁신경': 610,\n",
       " '▁빨리': 611,\n",
       " '▁부': 612,\n",
       " '▁날이': 613,\n",
       " '▁좋아해': 614,\n",
       " '▁잔': 615,\n",
       " '줄': 616,\n",
       " '▁모습': 617,\n",
       " '▁추억': 618,\n",
       " '냐': 619,\n",
       " '▁만나고': 620,\n",
       " '치': 621,\n",
       " '▁벌써': 622,\n",
       " '▁잘하고': 623,\n",
       " '금': 624,\n",
       " '▁꽃': 625,\n",
       " '▁귀': 626,\n",
       " '▁6': 627,\n",
       " '▁무': 628,\n",
       " '▁만들': 629,\n",
       " '▁않았': 630,\n",
       " '▁아픈': 631,\n",
       " '▁두': 632,\n",
       " '▁부모님': 633,\n",
       " '▁4': 634,\n",
       " '▁언젠': 635,\n",
       " '▁얼굴': 636,\n",
       " '▁주': 637,\n",
       " '▁먹어야': 638,\n",
       " '▁사이': 639,\n",
       " '▁이별이': 640,\n",
       " '▁넘': 641,\n",
       " '날': 642,\n",
       " '었어': 643,\n",
       " '▁감기': 644,\n",
       " '찍': 645,\n",
       " '▁괜찮은': 646,\n",
       " '▁사람들': 647,\n",
       " '▁끝나': 648,\n",
       " '제': 649,\n",
       " '▁걸까': 650,\n",
       " '▁이상': 651,\n",
       " '▁갖': 652,\n",
       " '달': 653,\n",
       " '해봐요': 654,\n",
       " '▁생각나': 655,\n",
       " '▁만난': 656,\n",
       " '▁가져': 657,\n",
       " '▁자신이': 658,\n",
       " '▁말이': 659,\n",
       " '듯': 660,\n",
       " '▁먹': 661,\n",
       " '▁잠시': 662,\n",
       " '▁바람': 663,\n",
       " '▁가능': 664,\n",
       " '▁만남': 665,\n",
       " '▁힘내세요': 666,\n",
       " '▁맞': 667,\n",
       " '▁신경쓰지': 668,\n",
       " '드릴': 669,\n",
       " '달라고': 670,\n",
       " '▁약': 671,\n",
       " '▁많': 672,\n",
       " '▁예쁘': 673,\n",
       " '▁예뻐': 674,\n",
       " '▁아픔': 675,\n",
       " '▁줘': 676,\n",
       " '▁아닌데': 677,\n",
       " '나요': 678,\n",
       " '▁것이': 679,\n",
       " '▁믿어요': 680,\n",
       " '▁적': 681,\n",
       " '▁소리': 682,\n",
       " '▁뿐이에요': 683,\n",
       " '▁되길': 684,\n",
       " '▁사귀고': 685,\n",
       " '▁하는데': 686,\n",
       " '▁되지': 687,\n",
       " '실': 688,\n",
       " '만에': 689,\n",
       " '봐': 690,\n",
       " '릴': 691,\n",
       " '거야': 692,\n",
       " '▁금': 693,\n",
       " '▁힘들다': 694,\n",
       " '트': 695,\n",
       " '▁습관': 696,\n",
       " '▁티': 697,\n",
       " '▁재미': 698,\n",
       " '▁바쁘': 699,\n",
       " '▁안해': 700,\n",
       " '▁슬픈': 701,\n",
       " '▁직장': 702,\n",
       " '▁어려워': 703,\n",
       " '일째': 704,\n",
       " '▁여친이': 705,\n",
       " '▁힘이': 706,\n",
       " '▁궁금해': 707,\n",
       " '▁남편이': 708,\n",
       " '▁좋겠': 709,\n",
       " '신': 710,\n",
       " '▁되었': 711,\n",
       " '▁잘못': 712,\n",
       " '▁다가가': 713,\n",
       " '▁주무': 714,\n",
       " '▁지': 715,\n",
       " '▁있었나봐요': 716,\n",
       " '▁알바': 717,\n",
       " '▁원하는': 718,\n",
       " '▁받고': 719,\n",
       " '▁나서': 720,\n",
       " '▁찾아보': 721,\n",
       " '▁전에': 722,\n",
       " '졌어': 723,\n",
       " '▁학교': 724,\n",
       " '▁호감': 725,\n",
       " '▁여자애': 726,\n",
       " '것': 727,\n",
       " '없이': 728,\n",
       " '▁동': 729,\n",
       " '▁게임': 730,\n",
       " '▁연락하고': 731,\n",
       " '번': 732,\n",
       " '▁아는': 733,\n",
       " '▁보면': 734,\n",
       " '▁삶': 735,\n",
       " '▁위해': 736,\n",
       " '▁화장': 737,\n",
       " '▁곧': 738,\n",
       " '▁자체': 739,\n",
       " '▁힘들게': 740,\n",
       " '▁필요하': 741,\n",
       " '▁건강': 742,\n",
       " '▁최고': 743,\n",
       " '드려': 744,\n",
       " '▁못하겠어': 745,\n",
       " '▁일어나': 746,\n",
       " '▁막': 747,\n",
       " '발': 748,\n",
       " '▁뭐야': 749,\n",
       " '▁썸남이': 750,\n",
       " '통': 751,\n",
       " '▁여유': 752,\n",
       " '▁사귀는': 753,\n",
       " '해야': 754,\n",
       " '▁긴': 755,\n",
       " '▁쉽': 756,\n",
       " '▁만': 757,\n",
       " '▁가슴': 758,\n",
       " '지는': 759,\n",
       " '▁이해': 760,\n",
       " '해야지': 761,\n",
       " '▁법': 762,\n",
       " '겠지만': 763,\n",
       " '▁옷': 764,\n",
       " '보': 765,\n",
       " '▁나중에': 766,\n",
       " '▁즐거': 767,\n",
       " '▁귀찮아': 768,\n",
       " '▁헤어지': 769,\n",
       " '▁괜찮을까': 770,\n",
       " '야겠다': 771,\n",
       " '▁꿈에': 772,\n",
       " '▁감': 773,\n",
       " '▁사랑했던': 774,\n",
       " '▁연락해': 775,\n",
       " '▁확인해': 776,\n",
       " '▁당': 777,\n",
       " '▁선': 778,\n",
       " '▁따뜻': 779,\n",
       " '▁못해': 780,\n",
       " '▁먹으면': 781,\n",
       " '▁다음에': 782,\n",
       " '▁싫다': 783,\n",
       " '▁생각할': 784,\n",
       " '▁그분': 785,\n",
       " '▁축하': 786,\n",
       " '▁별로': 787,\n",
       " '▁해주세요': 788,\n",
       " '▁되어': 789,\n",
       " '▁챙겨': 790,\n",
       " '▁좋아하면': 791,\n",
       " '▁생겼': 792,\n",
       " '▁보통': 793,\n",
       " '▁자신감': 794,\n",
       " '▁만났어': 795,\n",
       " '▁확실한': 796,\n",
       " '▁물어': 797,\n",
       " '▁소중': 798,\n",
       " '용': 799,\n",
       " '▁힘들지': 800,\n",
       " '▁코': 801,\n",
       " '▁설레': 802,\n",
       " '▁차이': 803,\n",
       " '▁행복해': 804,\n",
       " '▁그녀를': 805,\n",
       " '▁가기': 806,\n",
       " '▁물어보는': 807,\n",
       " '▁세상': 808,\n",
       " '▁말씀': 809,\n",
       " '▁위로': 810,\n",
       " '▁좋아하게': 811,\n",
       " '답': 812,\n",
       " '▁중에': 813,\n",
       " '▁많아요': 814,\n",
       " '했습니다': 815,\n",
       " '디': 816,\n",
       " '▁비싸': 817,\n",
       " '▁맛': 818,\n",
       " '▁우산': 819,\n",
       " '▁작은': 820,\n",
       " '▁짝녀한테': 821,\n",
       " '▁맨날': 822,\n",
       " '▁중요하지': 823,\n",
       " '▁미리': 824,\n",
       " '▁답': 825,\n",
       " '▁못하는': 826,\n",
       " '중': 827,\n",
       " '내': 828,\n",
       " '▁목': 829,\n",
       " '▁친구한테': 830,\n",
       " '▁괜찮': 831,\n",
       " '▁말해': 832,\n",
       " '▁잠이': 833,\n",
       " '▁연인': 834,\n",
       " '▁맛있는': 835,\n",
       " '▁첫사랑': 836,\n",
       " '▁끝이': 837,\n",
       " '▁봐': 838,\n",
       " '▁힘들겠지': 839,\n",
       " '▁받을': 840,\n",
       " '있는': 841,\n",
       " '▁했어': 842,\n",
       " '▁표현': 843,\n",
       " '▁안녕': 844,\n",
       " '▁없이': 845,\n",
       " '▁배': 846,\n",
       " '▁먹어': 847,\n",
       " '▁다를': 848,\n",
       " '▁간다': 849,\n",
       " '▁없네요': 850,\n",
       " '▁곳이': 851,\n",
       " '▁이별후': 852,\n",
       " '▁힘': 853,\n",
       " '▁차단': 854,\n",
       " '며': 855,\n",
       " '▁고생': 856,\n",
       " 'ᅲᅲ': 857,\n",
       " '▁종교': 858,\n",
       " '▁아프': 859,\n",
       " '▁기회': 860,\n",
       " '▁생길': 861,\n",
       " '▁시험': 862,\n",
       " '▁잠깐': 863,\n",
       " '▁주는': 864,\n",
       " '▁헤어졌습니다': 865,\n",
       " '▁위': 866,\n",
       " '▁카페': 867,\n",
       " '▁책': 868,\n",
       " '▁바쁜': 869,\n",
       " '▁편이': 870,\n",
       " '사': 871,\n",
       " '▁하늘': 872,\n",
       " '▁밤': 873,\n",
       " '▁놀아': 874,\n",
       " '▁대해': 875,\n",
       " '▁떠나': 876,\n",
       " '▁연락해도': 877,\n",
       " '을까': 878,\n",
       " '▁실수': 879,\n",
       " '▁이별의': 880,\n",
       " '▁정신': 881,\n",
       " '▁알게': 882,\n",
       " '다가': 883,\n",
       " '▁진정': 884,\n",
       " '건가': 885,\n",
       " '▁글': 886,\n",
       " '▁순간': 887,\n",
       " '▁약속': 888,\n",
       " '▁가야': 889,\n",
       " '▁보여': 890,\n",
       " '보면': 891,\n",
       " '줘': 892,\n",
       " '▁좋아하는데': 893,\n",
       " '▁전여친': 894,\n",
       " '▁쓰': 895,\n",
       " '림': 896,\n",
       " '란': 897,\n",
       " '▁멋진': 898,\n",
       " '▁분위기': 899,\n",
       " '▁알려줘': 900,\n",
       " '들이': 901,\n",
       " '▁싶네': 902,\n",
       " '했는데': 903,\n",
       " '▁만나지': 904,\n",
       " '▁같습니다': 905,\n",
       " '▁별': 906,\n",
       " '▁절대': 907,\n",
       " '▁알고': 908,\n",
       " '▁편하': 909,\n",
       " '▁건지': 910,\n",
       " '갈': 911,\n",
       " '▁받는': 912,\n",
       " '▁돈이': 913,\n",
       " '▁아닌지': 914,\n",
       " '사람을': 915,\n",
       " '줄까': 916,\n",
       " '▁모르': 917,\n",
       " '▁사랑할': 918,\n",
       " '▁타고': 919,\n",
       " '▁거짓말': 920,\n",
       " '▁사랑해': 921,\n",
       " '▁되네': 922,\n",
       " '▁상관': 923,\n",
       " '▁모': 924,\n",
       " '▁일을': 925,\n",
       " '이라면': 926,\n",
       " '▁안되는': 927,\n",
       " '울': 928,\n",
       " '집': 929,\n",
       " '▁즐기': 930,\n",
       " '▁느낌이': 931,\n",
       " '▁복': 932,\n",
       " '▁그래요': 933,\n",
       " '소': 934,\n",
       " '▁않고': 935,\n",
       " '린': 936,\n",
       " '▁봐요': 937,\n",
       " '덧': 938,\n",
       " '▁보지': 939,\n",
       " '▁봄': 940,\n",
       " '▁힘들어요': 941,\n",
       " '▁괜': 942,\n",
       " '▁자존감': 943,\n",
       " '▁드디어': 944,\n",
       " '▁헷갈리': 945,\n",
       " '▁뭔지': 946,\n",
       " '▁둘': 947,\n",
       " '▁파': 948,\n",
       " '▁노력하': 949,\n",
       " '겠어': 950,\n",
       " '텐데': 951,\n",
       " '▁받아들이는': 952,\n",
       " '▁사귀': 953,\n",
       " '▁죽을': 954,\n",
       " '가요': 955,\n",
       " '▁환승': 956,\n",
       " '▁드는': 957,\n",
       " '▁안되': 958,\n",
       " '▁편': 959,\n",
       " '▁남친이': 960,\n",
       " '▁여자애가': 961,\n",
       " '▁좋은데': 962,\n",
       " '▁살아': 963,\n",
       " '▁서로에': 964,\n",
       " '▁첫': 965,\n",
       " '▁됐어': 966,\n",
       " '▁좋겠죠': 967,\n",
       " '▁탈': 968,\n",
       " '▁먹을': 969,\n",
       " '▁폰': 970,\n",
       " '왔어': 971,\n",
       " '▁관리': 972,\n",
       " '▁미련이': 973,\n",
       " '▁데': 974,\n",
       " '▁남자들': 975,\n",
       " '가서': 976,\n",
       " '▁월급': 977,\n",
       " '엔': 978,\n",
       " '▁지켜': 979,\n",
       " '▁자책하지': 980,\n",
       " '▁매': 981,\n",
       " '▁떨려': 982,\n",
       " '▁않는다면': 983,\n",
       " '▁장': 984,\n",
       " '▁인기': 985,\n",
       " '▁뭔가': 986,\n",
       " '▁아닐까요': 987,\n",
       " '▁나가': 988,\n",
       " '▁방법이': 989,\n",
       " '▁문자': 990,\n",
       " '▁시기': 991,\n",
       " '▁그러면': 992,\n",
       " '▁분': 993,\n",
       " '▁뭐라고': 994,\n",
       " '▁개': 995,\n",
       " '▁세': 996,\n",
       " '겠다': 997,\n",
       " '▁있지': 998,\n",
       " '▁사랑하고': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "EAGoG9WRHWUd"
   },
   "outputs": [],
   "source": [
    "# 학습 데이터를 생성한다. (인코더 입력용, 디코더 입력용, 디코더 출력용)\n",
    "MAX_LEN = 15    # subword 길이\n",
    "enc_input = []\n",
    "dec_input = []\n",
    "dec_output = []\n",
    "\n",
    "for Q, A in zip(question, answer):\n",
    "    # Encoder 입력\n",
    "    enc_i = sp.encode_as_ids(Q)\n",
    "    enc_input.append(enc_i)\n",
    "\n",
    "    # Decoder 입력, 출력\n",
    "    dec_i = [sp.bos_id()]   # <BOS>에서 시작함\n",
    "    dec_o = []\n",
    "    for ans in sp.encode_as_ids(A):\n",
    "        dec_i.append(ans)\n",
    "        dec_o.append(ans)\n",
    "    dec_o.append(sp.eos_id())   # Decoder 출력은 <EOS>로 끝남.        \n",
    "    \n",
    "    # dec_o는 <EOS>가 마지막에 들어있다. 나중에 pad_sequences()에서 <EOS>가\n",
    "    # 잘려 나가지 않도록 MAX_LEN 위치에 <EOS>를 넣어준다.\n",
    "    if len(dec_o) > MAX_LEN:\n",
    "        dec_o[MAX_LEN] = sp.eos_id()\n",
    "        \n",
    "    dec_input.append(dec_i)\n",
    "    dec_output.append(dec_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "W2rZzHTMUCiG"
   },
   "outputs": [],
   "source": [
    "# 각 문장의 길이를 맞추고 남는 부분에 padding을 삽입한다.\n",
    "enc_input = pad_sequences(enc_input, maxlen=MAX_LEN, value = sp.pad_id(), padding='post', truncating='post')\n",
    "dec_input = pad_sequences(dec_input, maxlen=MAX_LEN, value = sp.pad_id(), padding='post', truncating='post')\n",
    "dec_output = pad_sequences(dec_output, maxlen=MAX_LEN, value = sp.pad_id(), padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "_DxQCfaqUsDA",
    "outputId": "11492a84-de3b-4cd5-ca12-e4f1a58596a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1지망 학교 떨어졌어', '위로해 드립니다')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question[1], answer[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "M0rPQ5C6UGZk",
    "outputId": "a9cb771d-929e-4a0e-bebf-2e6d121984e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 251, 7084,  724, 1598,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Jp6jwabqUP72",
    "outputId": "1e2c9dc5-bccf-4c94-c18f-eb67d746781f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2, 1421,  143, 1465,   91,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "jwXJiuHmUSDC",
    "outputId": "fd38f2f3-d94b-4303-879f-3a061fc283a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1421,  143, 1465,   91,    3,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TP6ipDy4Jjsd"
   },
   "outputs": [],
   "source": [
    "# 사전과 학습 데이터를 저장한다.\n",
    "with open('data/chatbot_voc.pkl', 'wb') as f:\n",
    "    pickle.dump([word2idx, idx2word], f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# BLEU 평가를 위해 que_test와 ans_test를 저장해 둔다.\n",
    "with open('data/chatbot_train.pkl', 'wb') as f:\n",
    "    pickle.dump([enc_input, dec_input, dec_output], f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZpH0dZAMwnh"
   },
   "source": [
    "## Sequence to Sequence Model\n",
    "\n",
    "  - 시퀀스 형태의 입력값을 시퀀스 형태의 출력으로 만드는 모델\n",
    "  - 하나의 텍스트 문장이 입력으로 들어오면 하나의 텍스트 문장을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "o_itRUXAcu67"
   },
   "outputs": [],
   "source": [
    "# Seq2Seq 모델를 이용한 ChatBot : 학습 모듈 (Teacher forcing)\n",
    "#\n",
    "# 관련 논문 : Kyunghyun Cho, et. al., 2014,\n",
    "#             Learning Phrase Representations using RNN Encoder–Decoder \n",
    "#             for Statistical Machine Translation\n",
    "#\n",
    "# 저작자: 2021.05.26, 조성현 (blog.naver.com/chunjein)\n",
    "# copyright: SNS 등에 공개할 때는 출처에 저작자를 명시해 주시기 바랍니다.\n",
    "# -----------------------------------------------------------------------\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.layers import Embedding, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "O-jiJg6Icuwq",
    "outputId": "c8ba57fc-29d4-4ea2-acd1-2bbd337221bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "# 작업 디렉토리를 변경한다.\n",
    "%cd '/content/drive/My Drive/Colab Notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PGN7wA1GdhQK"
   },
   "outputs": [],
   "source": [
    "# Sub-word 사전 읽어온다.\n",
    "with open('data/chatbot_voc.pkl', 'rb') as f:\n",
    "    word2idx,  idx2word = pickle.load(f)\n",
    "\n",
    "# 학습 데이터 : 인코딩, 디코딩 입력, 디코딩 출력을 읽어온다.\n",
    "with open('data/chatbot_train.pkl', 'rb') as f:\n",
    "    trainXE, trainXD, trainYD = pickle.load(f)\n",
    "\t\n",
    "VOCAB_SIZE = len(idx2word)\n",
    "EMB_SIZE = 128\n",
    "LSTM_HIDDEN = 128\n",
    "MODEL_PATH = 'data/chatbot_trained.h5'\n",
    "LOAD_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "eStjUdHmd4N2",
    "outputId": "f5346e65-b645-40f2-cf6b-b881b9080b1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([259,   6, 100,  90,  36,   3,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainYD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "B7SXvOn2d5mT",
    "outputId": "cf6b80a1-2822-4612-cb74-d4dd1d90fbab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁하루', '가', '▁또', '▁가', '네요', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "print([idx2word[i] for i in trainYD[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "_UNbWN-sj5pV",
    "outputId": "731c019a-0932-4efb-d7b4-e0242ebe47b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "vMQwa9JgckGV",
    "outputId": "36623308-4a37-450a-d43c-773628972411"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 15)]         0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 15)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 15, 128)      1152000     ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 15, 128),    131584      ['embedding[0][0]']              \n",
      "                                 (None, 128),                                                     \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 15, 128),    131584      ['embedding[1][0]',              \n",
      "                                 (None, 128),                     'lstm[0][1]',                   \n",
      "                                 (None, 128)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 128),        131584      ['lstm[0][0]']                   \n",
      "                                 (None, 128),                                                     \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, 15, 128),    131584      ['lstm_2[0][0]',                 \n",
      "                                 (None, 128),                     'lstm_1[0][1]',                 \n",
      "                                 (None, 128)]                     'lstm_1[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 15, 9000)    1161000     ['lstm_3[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,839,336\n",
      "Trainable params: 2,839,336\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 워드 임베딩 레이어. Encoder와 decoder에서 공동으로 사용한다.\n",
    "K.clear_session()\n",
    "wordEmbedding = Embedding(input_dim=VOCAB_SIZE, output_dim=EMB_SIZE)\n",
    "\n",
    "# Encoder\n",
    "# -------\n",
    "# many-to-one으로 구성한다. 중간 출력은 필요 없고 decoder로 전달할 h와 c만\n",
    "# 필요하다. h와 c를 얻기 위해 return_state = True를 설정한다.\n",
    "encoderX = Input(batch_shape=(None, trainXE.shape[1]))\n",
    "encEMB = wordEmbedding(encoderX)\n",
    "encLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state = True)        # return_sequences: 중간출력을 2층으로 올려보내기 위해 필요\n",
    "encLSTM2 = LSTM(LSTM_HIDDEN, return_state = True)\n",
    "ey1, eh1, ec1 = encLSTM1(encEMB)    # LSTM 1층 \n",
    "_, eh2, ec2 = encLSTM2(ey1)       # LSTM 2층\n",
    "\n",
    "# Decoder\n",
    "# -------\n",
    "# many-to-many로 구성한다. target을 학습하기 위해서는 중간 출력이 필요하다.\n",
    "# 그리고 초기 h와 c는 encoder에서 출력한 값을 사용한다 (initial_state)\n",
    "# 최종 출력은 vocabulary의 인덱스인 one-hot 인코더이다.\n",
    "decoderX = Input(batch_shape=(None, trainXD.shape[1]))\n",
    "decEMB = wordEmbedding(decoderX)\n",
    "decLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
    "decLSTM2 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
    "dy1, _, _ = decLSTM1(decEMB, initial_state = [eh1, ec1])\n",
    "dy2, _, _ = decLSTM2(dy1, initial_state = [eh2, ec2])\n",
    "decOutput = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))\n",
    "outputY = decOutput(dy2)\n",
    "\n",
    "# Model\n",
    "# -----\n",
    "model = Model([encoderX, decoderX], outputY)\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.0005), \n",
    "              loss='sparse_categorical_crossentropy')\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    model.load_weights(MODEL_PATH)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "xzxOMAVDjzqk",
    "outputId": "70fd43e9-ca58-4200-da33-62ba67e9ae37"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-490ca54583c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 학습 결과를 저장한다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Loss history를 그린다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# 학습 (teacher forcing)\n",
    "# ----------------------\n",
    "# hist = model.fit([trainXE, trainXD], trainYD, batch_size = 512, epochs=50, shuffle=True)\n",
    "\n",
    "# 학습 결과를 저장한다\n",
    "model.save_weights(MODEL_PATH)\n",
    "\n",
    "# Loss history를 그린다\n",
    "plt.plot(hist.history['loss'], label='Train loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss history\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLy-d8r82ECr"
   },
   "source": [
    "## Chat Bot model (Seq2Seq를 이용한 챗봇모델 구현)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "4BLtuniV2IDp",
    "outputId": "c11e86a2-fbc0-44c2-f1d6-c7e61ae8e8fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |▎                               | 10 kB 18.8 MB/s eta 0:00:01\r",
      "\u001b[K     |▌                               | 20 kB 14.5 MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 30 kB 10.6 MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 40 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▍                              | 51 kB 4.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 61 kB 5.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 71 kB 5.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 81 kB 4.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 92 kB 4.7 MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 102 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 112 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 122 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 133 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 143 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 153 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 163 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 174 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 184 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 194 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 204 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 215 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 225 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 235 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 245 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 256 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 266 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 276 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 286 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 296 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 307 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 317 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 327 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 337 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 348 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 358 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 368 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 378 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 389 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 399 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 409 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 419 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 430 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 440 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 450 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 460 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 471 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 481 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 491 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 501 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 512 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 522 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 532 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 542 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 552 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 563 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 573 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 583 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 593 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 604 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 614 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 624 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 634 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 645 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 655 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 665 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 675 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 686 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 696 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 706 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 716 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 727 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 737 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 747 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 757 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 768 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 778 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 788 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 798 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 808 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 819 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 829 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 839 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 849 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 860 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 870 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 880 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 890 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 901 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 911 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 921 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 931 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 942 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 952 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 962 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 972 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 983 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 993 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 1.0 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 1.0 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.0 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 1.0 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 1.0 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 1.2 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 1.2 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 1.2 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 1.2 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 1.2 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 1.2 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.2 MB 5.1 MB/s \n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.96\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "q_bmYv2q2L2-"
   },
   "outputs": [],
   "source": [
    "# Seq2Seq 모델를 이용한 ChatBot : 채팅 모듈\n",
    "#\n",
    "# 관련 논문 : Kyunghyun Cho, et. al., 2014,\n",
    "#            Learning Phrase Representations using RNN Encoder–Decoder \n",
    "#            for Statistical Machine Translation\n",
    "#\n",
    "# 저작자: 2021.05.26, 조성현 (blog.naver.com/chunjein)\n",
    "# copyright: SNS 등에 공개할 때는 출처에 저작자를 명시해 주시기 바랍니다.\n",
    "# ----------------------------------------------------------------------\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.layers import Embedding, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "import sentencepiece as spm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "EoH7ctLD2_Eb",
    "outputId": "042ce285-50b9-4998-a234-dad6fd57b710"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "# 작업 디렉토리를 변경한다.\n",
    "%cd '/content/drive/My Drive/Colab Notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-Zj3n8Gd29qh"
   },
   "outputs": [],
   "source": [
    "# Sub-word 사전 읽어온다.\n",
    "with open('data/chatbot_voc.pkl', 'rb') as f:\n",
    "    word2idx,  idx2word = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "91GOvans3Ap4",
    "outputId": "31d17545-0007-4060-bb24-8994162c9d9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(idx2word)\n",
    "EMB_SIZE = 128\n",
    "LSTM_HIDDEN = 128\n",
    "MAX_LEN = 15            # 단어 시퀀스 길이\n",
    "MODEL_PATH = 'data/chatbot_trained.h5'\n",
    "\n",
    "# 데이터 전처리 과정에서 생성한 SentencePiece model을 불러온다.\n",
    "SPM_MODEL = \"data/chatbot_model.model\"\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(SPM_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "78WynWRQ2FoU"
   },
   "outputs": [],
   "source": [
    "# 워드 임베딩 레이어. Encoder와 decoder에서 공동으로 사용한다.\n",
    "K.clear_session()\n",
    "wordEmbedding = Embedding(input_dim=VOCAB_SIZE, output_dim=EMB_SIZE)\n",
    "\n",
    "# Encoder\n",
    "# -------\n",
    "# c는 long term, short term(의 비중?)을 컨트롤 하는 cell state\n",
    "encoderX = Input(batch_shape=(None, MAX_LEN))\n",
    "encEMB = wordEmbedding(encoderX)\n",
    "encLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state = True)\n",
    "encLSTM2 = LSTM(LSTM_HIDDEN, return_state = True)\n",
    "ey1, eh1, ec1 = encLSTM1(encEMB)    # LSTM 1층 \n",
    "_, eh2, ec2 = encLSTM2(ey1)         # LSTM 2층\n",
    "\n",
    "# Decoder\n",
    "# -------\n",
    "# Decoder는 1개 단어씩을 입력으로 받는다. (앞과 이 부분이 다름)\n",
    "# chat bot 학습때는 teacher forcing.\n",
    "decoderX = Input(batch_shape=(None, 1))\n",
    "decEMB = wordEmbedding(decoderX)\n",
    "decLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
    "decLSTM2 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
    "dy1, _, _ = decLSTM1(decEMB, initial_state = [eh1, ec1])\n",
    "dy2, _, _ = decLSTM2(dy1, initial_state = [eh2, ec2])\n",
    "decOutput = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))\n",
    "outputY = decOutput(dy2)\n",
    "\n",
    "# Model\n",
    "# -----\n",
    "model = Model([encoderX, decoderX], outputY)\n",
    "model.load_weights(MODEL_PATH)\n",
    "\n",
    "\n",
    "\n",
    "# Chatting용 model\n",
    "model_enc = Model(encoderX, [eh1, ec1, eh2, ec2])\n",
    "\n",
    "ih1 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "ic1 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "ih2 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "ic2 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "\n",
    "dec_output1, dh1, dc1 = decLSTM1(decEMB, initial_state = [ih1, ic1])\n",
    "dec_output2, dh2, dc2 = decLSTM2(dec_output1, initial_state = [ih2, ic2])\n",
    "\n",
    "dec_output = decOutput(dec_output2)\n",
    "model_dec = Model([decoderX, ih1, ic1, ih2, ic2], [dec_output, dh1, dc1, dh2, dc2])\n",
    "\n",
    "# -----------\n",
    "# Question을 입력받아 Answer를 생성한다.\n",
    "def genAnswer(question):\n",
    "    question = question[np.newaxis, :]\n",
    "    init_h1, init_c1, init_h2, init_c2 = model_enc.predict(question)\n",
    "\n",
    "    # 시작 단어는 <BOS>로 한다.\n",
    "    word = np.array(sp.bos_id()).reshape(1, 1)\n",
    "\n",
    "    answer = []\n",
    "    for i in range(MAX_LEN):\n",
    "        dY, next_h1, next_c1, next_h2, next_c2 = model_dec.predict([word, init_h1, init_c1, init_h2, init_c2])\n",
    "        \n",
    "        # 디코더의 출력은 vocabulary에 대응되는 one-hot이다.\n",
    "        # argmax로 해당 단어를 채택한다.\n",
    "        print(dY.shape)     # (1, 1, 9000) => len(word2idx) = 9000\n",
    "        print(dY)\n",
    "        random_pick = random.randrange(len(dY[0, 0]))\n",
    "        \n",
    "        # nextWord = np.argmax(dY[0, 0])\n",
    "        nextWord = random_pick\n",
    "\n",
    "        # 예상 단어가 <EOS>이거나 <PAD>이면 더 이상 예상할 게 없다.\n",
    "        if nextWord == sp.eos_id() or nextWord == sp.pad_id():\n",
    "            break\n",
    "        \n",
    "        # 다음 예상 단어인 디코더의 출력을 answer에 추가한다.\n",
    "        answer.append(idx2word[nextWord])\n",
    "        \n",
    "        # 디코더의 다음 recurrent를 위해 입력 데이터와 hidden 값을\n",
    "        # 준비한다. 입력은 word이고, hidden은 h와 c이다.\n",
    "        word = np.array(nextWord).reshape(1,1)\n",
    "    \n",
    "        init_h1 = next_h1\n",
    "        init_c1 = next_c1\n",
    "        init_h2 = next_h2\n",
    "        init_c2 = next_c2\n",
    "        \n",
    "    return sp.decode_pieces(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_kmcFWFT8Cys"
   },
   "outputs": [],
   "source": [
    "def make_question(que_string):\n",
    "    q_idx = []\n",
    "    for x in sp.encode_as_pieces(que_string):\n",
    "        if x in word2idx:\n",
    "            q_idx.append(word2idx[x])\n",
    "        else:\n",
    "            q_idx.append(sp.unk_id())   # out-of-vocabulary (OOV)\n",
    "    \n",
    "    # <PAD>를 삽입한다.\n",
    "    if len(q_idx) < MAX_LEN:\n",
    "        q_idx.extend([sp.pad_id()] * (MAX_LEN - len(q_idx)))\n",
    "    else:\n",
    "        q_idx = q_idx[0:MAX_LEN]\n",
    "    return q_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "r0VcJcrZ8Csr"
   },
   "outputs": [],
   "source": [
    "# Chatting\n",
    "# dummy : 최초 1회는 모델을 로드하는데 약간의 시간이 걸리므로 이것을 가리기 위함.\n",
    "def chatting(n=100):\n",
    "    for i in range(n):\n",
    "        question = input('Q : ')\n",
    "        \n",
    "        if  question == 'quit':\n",
    "            break\n",
    "        \n",
    "        q_idx = make_question(question)\n",
    "        answer = genAnswer(np.array(q_idx))\n",
    "        print('A :', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ZzkVmNWn4IZv",
    "outputId": "6d50a340-e7c1-4d31-af42-d91b69bc1c3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seq2Seq ChatBot (ver. 1.0)\n",
      "Chatting 모듈을 로드하고 있습니다 ...\n",
      "(1, 1, 9000)\n",
      "[[[2.8888815e-07 9.3303330e-09 9.0820755e-09 ... 8.0014768e-09\n",
      "   6.0870402e-09 7.5507476e-09]]]\n",
      "(1, 1, 9000)\n",
      "[[[3.4904838e-07 5.6802403e-08 7.3648216e-09 ... 6.6628068e-09\n",
      "   6.8739134e-09 6.5793069e-09]]]\n",
      "(1, 1, 9000)\n",
      "[[[1.2962891e-05 7.2490889e-06 4.8924118e-08 ... 3.9227032e-08\n",
      "   4.0696484e-08 4.1159161e-08]]]\n",
      "(1, 1, 9000)\n",
      "[[[3.1682546e-04 1.6736411e-05 6.2273536e-08 ... 4.6575384e-08\n",
      "   5.1000150e-08 5.4509911e-08]]]\n",
      "(1, 1, 9000)\n",
      "[[[4.2448264e-05 2.3891438e-12 8.0371239e-09 ... 5.8274305e-09\n",
      "   6.3216961e-09 6.4201826e-09]]]\n",
      "(1, 1, 9000)\n",
      "[[[6.5838508e-06 7.2073528e-11 3.9609556e-09 ... 2.9595997e-09\n",
      "   3.3970957e-09 3.4606900e-09]]]\n",
      "(1, 1, 9000)\n",
      "[[[4.3749413e-08 4.0472833e-13 7.5987627e-10 ... 6.2952837e-10\n",
      "   6.4857714e-10 6.4174766e-10]]]\n",
      "(1, 1, 9000)\n",
      "[[[6.0472367e-08 1.1730505e-10 1.6637413e-09 ... 1.5241192e-09\n",
      "   1.6585041e-09 1.5470845e-09]]]\n",
      "(1, 1, 9000)\n",
      "[[[1.9577182e-04 2.0250167e-13 4.9714823e-09 ... 4.1488013e-09\n",
      "   3.9661145e-09 4.1476858e-09]]]\n",
      "(1, 1, 9000)\n",
      "[[[1.1192335e-05 7.2449987e-14 5.5082688e-10 ... 4.5595872e-10\n",
      "   4.5228277e-10 4.5379059e-10]]]\n",
      "(1, 1, 9000)\n",
      "[[[3.0372225e-05 4.7699268e-14 2.1129367e-09 ... 1.6505076e-09\n",
      "   1.6905476e-09 1.7014620e-09]]]\n",
      "(1, 1, 9000)\n",
      "[[[1.5085069e-05 1.2953125e-14 2.9522316e-09 ... 2.2726914e-09\n",
      "   2.3524360e-09 2.3477789e-09]]]\n",
      "(1, 1, 9000)\n",
      "[[[1.12468064e-04 4.64135987e-11 1.78657249e-08 ... 1.51940274e-08\n",
      "   1.56870161e-08 1.48725503e-08]]]\n",
      "(1, 1, 9000)\n",
      "[[[4.55542991e-04 1.34900812e-13 1.03693845e-08 ... 8.41457126e-09\n",
      "   9.01241126e-09 8.62384919e-09]]]\n",
      "(1, 1, 9000)\n",
      "[[[1.3441452e-05 7.4010927e-15 3.3347165e-09 ... 2.6507030e-09\n",
      "   2.8239362e-09 2.6822762e-09]]]\n",
      "ChatBot이 준비 됐습니다.\n",
      "Q : quit\n"
     ]
    }
   ],
   "source": [
    "####### Chatting 시작 #######\n",
    "print(\"\\nSeq2Seq ChatBot (ver. 1.0)\")\n",
    "print(\"Chatting 모듈을 로드하고 있습니다 ...\")\n",
    "\n",
    "# 처음 1회는 시간이 걸리기 때문에 dummy question을 입력한다.\n",
    "answer = genAnswer(np.zeros(MAX_LEN))\n",
    "print(\"ChatBot이 준비 됐습니다.\")\n",
    "\n",
    "# 채팅을 시작한다.\n",
    "chatting(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jIUFvd0y7iQ1"
   },
   "outputs": [],
   "source": [
    "# train data:\n",
    "#  ('허기져', '챙겨 드세요'),\n",
    "#  ('맥주 소주 어떤거 마실까', '소맥이요'),\n",
    "#  ('교양 수업 재밌어', '저도 듣고 싶어요'),\n",
    "#  ('권태기 이별', '극복하거나 이별하거나 둘 중 하나죠'),\n",
    "#  ('읽씹은 아프네', '상대방에 대한 예의가 없네요'),\n",
    "#  ('신혼여행 어디로 갈까', '못 가본 곳으로 가보세요'),\n",
    "#  ('반 배정 잘 될까', '잘 되길 바랍니다'),\n",
    "#  ('친구가 다 떠나서 내가 못났나 싶어', '지난 인연에 연연해하지 마세요'),\n",
    "#  ('뒤돌아 보지 말고 나가야 하는데', '살짝 뒤돌아봐도 괜찮아요')\n",
    "#  ('소오름 쫙', '좋은 일이길 바랍니다'),\n",
    "#  ('고백은 어떻게 하는거야', '솔직한 마음으로 다가가는 거죠'),\n",
    "#  ('참 잘낫네', '진정하셔요'),\n",
    "#  ('늘 빡빡하게 살기 힘드네', '여유가 생기길 바랍니다'),\n",
    "#  ('집까지 데려다줬는데 호감 그냥 매너', '호감이 있을 수도 있어요 그렇지만 조금 더 상황을 지켜보세요'),\n",
    "#  ('짝녀가 연락 안 되고 있는데 자나', '자고 있을지도 모르겠어요'),\n",
    "#  ('마음도 춥고 날씨도 춥고', '마음 감기 조심하세요'),\n",
    "#  ('죽었던 연애세포가 살아나는 것 같아', '좋은 소식이네요'),\n",
    "#  ('겨울에는 온천이지', '몸은 뜨겁고 머리는 차갑게'),\n",
    "#  ('소개팅 하고싶다', '친구한테 부탁해보세요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ygZalhsfApKi",
    "outputId": "65b61894-2879-4b29-d2f8-bdeb9ec91d6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88079708, 0.11920292])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = 0.3\n",
    "a = np.array([0.8, 0.2])\n",
    "np.exp(a/beta) / np.sum(np.exp(a/beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qeEvBIT1o3Ul"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0wi1FctuVo1"
   },
   "source": [
    "# beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2jmuhAwuWMC"
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece\n",
    "\n",
    "# Seq2Seq 모델를 이용한 ChatBot : 채팅 모듈\n",
    "#\n",
    "# 관련 논문 : Kyunghyun Cho, et. al., 2014,\n",
    "#            Learning Phrase Representations using RNN Encoder–Decoder \n",
    "#            for Statistical Machine Translation\n",
    "#\n",
    "# 저작자: 2021.05.26, 조성현 (blog.naver.com/chunjein)\n",
    "# copyright: SNS 등에 공개할 때는 출처에 저작자를 명시해 주시기 바랍니다.\n",
    "# ----------------------------------------------------------------------\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.layers import Embedding, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "import sentencepiece as spm\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "# 작업 디렉토리를 변경한다.\n",
    "# %cd '/content/drive/My Drive/Colab Notebooks'\n",
    "\n",
    "# Sub-word 사전 읽어온다.\n",
    "with open('data/chatbot_voc.pkl', 'rb') as f:\n",
    "    word2idx,  idx2word = pickle.load(f)\n",
    "\n",
    "VOCAB_SIZE = len(idx2word)\n",
    "EMB_SIZE = 128\n",
    "LSTM_HIDDEN = 128\n",
    "MAX_LEN = 15            # 단어 시퀀스 길이\n",
    "MODEL_PATH = 'data/chatbot_trained.h5'\n",
    "SOFT_BETA = 1.0\n",
    "\n",
    "# 데이터 전처리 과정에서 생성한 SentencePiece model을 불러온다.\n",
    "SPM_MODEL = \"data/chatbot_model.model\"\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(SPM_MODEL)\n",
    "\n",
    "# 워드 임베딩 레이어. Encoder와 decoder에서 공동으로 사용한다.\n",
    "K.clear_session()\n",
    "wordEmbedding = Embedding(input_dim=VOCAB_SIZE, output_dim=EMB_SIZE)\n",
    "\n",
    "# Encoder\n",
    "# -------\n",
    "encoderX = Input(batch_shape=(None, MAX_LEN))\n",
    "encEMB = wordEmbedding(encoderX)\n",
    "encLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state = True)\n",
    "encLSTM2 = LSTM(LSTM_HIDDEN, return_state = True)\n",
    "ey1, eh1, ec1 = encLSTM1(encEMB)    # LSTM 1층 \n",
    "_, eh2, ec2 = encLSTM2(ey1)         # LSTM 2층\n",
    "\n",
    "# Decoder\n",
    "# -------\n",
    "decoderX = Input(batch_shape=(None, 1))\n",
    "decEMB = wordEmbedding(decoderX)\n",
    "decLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
    "decLSTM2 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
    "dy1, _, _ = decLSTM1(decEMB, initial_state = [eh1, ec1])\n",
    "dy2, _, _ = decLSTM2(dy1, initial_state = [eh2, ec2])\n",
    "decOutput = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))\n",
    "outputY = decOutput(dy2)\n",
    "\n",
    "model = Model([encoderX, decoderX], outputY)\n",
    "model.load_weights(MODEL_PATH)\n",
    "\n",
    "# Chatting model\n",
    "# --------------\n",
    "model_enc = Model(encoderX, [eh1, ec1, eh2, ec2])\n",
    "\n",
    "ih1 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "ic1 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "ih2 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "ic2 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "\n",
    "dec_output1, dh1, dc1 = decLSTM1(decEMB, initial_state = [ih1, ic1])\n",
    "dec_output2, dh2, dc2 = decLSTM2(dec_output1, initial_state = [ih2, ic2])\n",
    "\n",
    "dec_output = decOutput(dec_output2)\n",
    "model_dec = Model([decoderX, ih1, ic1, ih2, ic2], [dec_output, dh1, dc1, dh2, dc2])\n",
    "\n",
    "\n",
    "# 컴퓨터가 실숫값을 할당할때 8byte(double precision), 4byte(single precision) 할당이 있는데 8*8 = 64bit, 8*4 = 32bit 로 실숫값표시 => 정확도 차이가 있음\n",
    "# 4byte가 빨라서 GPU연산 내부적으로나 Keras, tensorflow 들은 주로 기본32bit 사용\n",
    "def rand_argmax(p, beta=1.2):\n",
    "    # 조절 변수인 beta를 사용해서 기존 softmax 확률값을 변형 시킨다.\n",
    "    p = np.asarray(p).astype('float64')\n",
    "    p = np.log(p + 1e-12) / beta\n",
    "\n",
    "    # new softmax\n",
    "    e = np.exp(p)\n",
    "    s = e / np.sum(e)\n",
    "\n",
    "    # new softmax 확률에 따라 단어 한 개를 선택한다.\n",
    "    probs = np.random.multinomial(1, s, 1)\n",
    "\n",
    "    return np.argmax(probs)\n",
    "\n",
    "# Question을 입력받아 Answer를 생성한다.\n",
    "def genAnswer(question):\n",
    "    question = question[np.newaxis, :]\n",
    "    init_h1, init_c1, init_h2, init_c2 = model_enc.predict(question)\n",
    "\n",
    "    # 시작 단어는 <BOS>로 한다.\n",
    "    word = np.array(sp.bos_id()).reshape(1, 1)\n",
    "\n",
    "    answer = []\n",
    "    for i in range(MAX_LEN):\n",
    "        dY, next_h1, next_c1, next_h2, next_c2 = model_dec.predict([word, init_h1, init_c1, init_h2, init_c2])\n",
    "        \n",
    "        # 디코더의 출력은 vocabulary에 대응되는 one-hot이다.\n",
    "        # nextWord = np.argmax(dY[0, 0])\n",
    "        nextWord = rand_argmax(dY[0, 0])\n",
    "\n",
    "        # 예상 단어가 <EOS>이거나 <PAD>이면 더 이상 예상할 게 없다.\n",
    "        if nextWord == sp.eos_id() or nextWord == sp.pad_id():\n",
    "            break\n",
    "        \n",
    "        # 다음 예상 단어인 디코더의 출력을 answer에 추가한다.\n",
    "        answer.append(idx2word[nextWord])\n",
    "        \n",
    "        # 디코더의 다음 recurrent를 위해 입력 데이터와 hidden 값을\n",
    "        word = np.array(nextWord).reshape(1,1)\n",
    "    \n",
    "        init_h1 = next_h1\n",
    "        init_c1 = next_c1\n",
    "        init_h2 = next_h2\n",
    "        init_c2 = next_c2\n",
    "        \n",
    "    return sp.decode_pieces(answer)\n",
    "\n",
    "def make_question(que_string):\n",
    "    q_idx = []\n",
    "    for x in sp.encode_as_pieces(que_string):\n",
    "        if x in word2idx:\n",
    "            q_idx.append(word2idx[x])\n",
    "        else:\n",
    "            q_idx.append(sp.unk_id())   # out-of-vocabulary (OOV)\n",
    "    \n",
    "    # <PAD>를 삽입한다.\n",
    "    if len(q_idx) < MAX_LEN:\n",
    "        q_idx.extend([sp.pad_id()] * (MAX_LEN - len(q_idx)))\n",
    "    else:\n",
    "        q_idx = q_idx[0:MAX_LEN]\n",
    "    return q_idx\n",
    "\n",
    "# Chatting\n",
    "# dummy : 최초 1회는 모델을 로드하는데 약간의 시간이 걸리므로 이것을 가리기 위함.\n",
    "def chatting(n=100):\n",
    "    for i in range(n):\n",
    "        question = input('Q : ')\n",
    "        \n",
    "        if  question == 'quit':\n",
    "            break\n",
    "        \n",
    "        q_idx = make_question(question)\n",
    "        answer = genAnswer(np.array(q_idx))\n",
    "        print('A :', answer)\n",
    "\n",
    "####### Chatting 시작 #######\n",
    "print(\"\\nSeq2Seq ChatBot (ver. 1.0)\")\n",
    "print(\"Chatting 모듈을 로드하고 있습니다 ...\")\n",
    "\n",
    "# 처음 1회는 시간이 걸리기 때문에 dummy question을 입력한다.\n",
    "answer = genAnswer(np.zeros(MAX_LEN))\n",
    "print(\"ChatBot이 준비 됐습니다.\")\n",
    "\n",
    "# 채팅을 시작한다.\n",
    "chatting(100)\n",
    "\n",
    "# train data:\n",
    "#  ('허기져', '챙겨 드세요'),\n",
    "#  ('맥주 소주 어떤거 마실까', '소맥이요'),\n",
    "#  ('교양 수업 재밌어', '저도 듣고 싶어요'),\n",
    "#  ('권태기 이별', '극복하거나 이별하거나 둘 중 하나죠'),\n",
    "#  ('읽씹은 아프네', '상대방에 대한 예의가 없네요'),\n",
    "#  ('신혼여행 어디로 갈까', '못 가본 곳으로 가보세요'),\n",
    "#  ('반 배정 잘 될까', '잘 되길 바랍니다'),\n",
    "#  ('친구가 다 떠나서 내가 못났나 싶어', '지난 인연에 연연해하지 마세요'),\n",
    "#  ('뒤돌아 보지 말고 나가야 하는데', '살짝 뒤돌아봐도 괜찮아요')\n",
    "#  ('소오름 쫙', '좋은 일이길 바랍니다'),\n",
    "#  ('고백은 어떻게 하는거야', '솔직한 마음으로 다가가는 거죠'),\n",
    "#  ('참 잘낫네', '진정하셔요'),\n",
    "#  ('늘 빡빡하게 살기 힘드네', '여유가 생기길 바랍니다'),\n",
    "#  ('집까지 데려다줬는데 호감 그냥 매너', '호감이 있을 수도 있어요 그렇지만 조금 더 상황을 지켜보세요'),\n",
    "#  ('짝녀가 연락 안 되고 있는데 자나', '자고 있을지도 모르겠어요'),\n",
    "#  ('마음도 춥고 날씨도 춥고', '마음 감기 조심하세요'),\n",
    "#  ('죽었던 연애세포가 살아나는 것 같아', '좋은 소식이네요'),\n",
    "#  ('겨울에는 온천이지', '몸은 뜨겁고 머리는 차갑게'),\n",
    "#  ('소개팅 하고싶다', '친구한테 부탁해보세요')\n",
    "\n",
    "beta = 1.0\n",
    "a = np.array([0.6, 0.1, 0.1, 0.2])\n",
    "s = np.exp(a / beta) / np.sum(np.exp(a / beta))\n",
    "s\n",
    "\n",
    "for i in range(10):\n",
    "    print(np.argmax(np.random.binomial(1, s)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArDN6qOcu7-v"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "0329(챗봇).ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
