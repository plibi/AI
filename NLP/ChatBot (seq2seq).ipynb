{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGeV53DoJmLB"
   },
   "source": [
    "# 챗봇\n",
    "\n",
    "1. 데이터 분석\n",
    "2. 데이터 전처리\n",
    "3. 모델링\n",
    "    - 챗봇 모델 평가는 어떻게 할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bc_0_3BqJ2c6"
   },
   "source": [
    "## 1. 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMWHMsFCJnuW"
   },
   "source": [
    "### Sentence piece를 이용해 subword로 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T23:41:50.519443Z",
     "start_time": "2022-12-25T23:41:44.512383Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "WR8EReF8H53D",
    "outputId": "83ff155c-dbc3-4259-db91-40a82e4be2b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.97\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T23:41:40.379197Z",
     "start_time": "2022-12-25T23:41:40.379197Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "DtF4afUOH8mw",
    "outputId": "a61692b1-7e23-4daf-d5fa-9f397c27d797"
   },
   "outputs": [],
   "source": [
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "# 작업 디렉토리를 변경한다.\n",
    "# %cd '/content/drive/My Drive/Colab Notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T23:41:53.634914Z",
     "start_time": "2022-12-25T23:41:53.588876Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ERVSZ--gV3Vy",
    "outputId": "8d4c9fd9-bc7d-4c0b-bbf5-db0e01664ab6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T23:41:55.842434Z",
     "start_time": "2022-12-25T23:41:55.822487Z"
    },
    "id": "d7KMb1-VI0yT"
   },
   "outputs": [],
   "source": [
    "# Seq2Seq ChatBot : 학습 데이터 모듈\n",
    "# Google의 Sentencepiece를 이용해서 학습 데이터를 생성한다.\n",
    "#\n",
    "# 저작자: 2021.05.26, 조성현 (blog.naver.com/chunjein)\n",
    "# copyright: SNS 등에 공개할 때는 출처에 저작자를 명시해 주시기 바랍니다.\n",
    "# -----------------------------------------------------------------------\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T23:41:57.068549Z",
     "start_time": "2022-12-25T23:41:56.999898Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8dexVvt2I12s",
    "outputId": "7b90011b-830f-410c-b211-c59e891b94bb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 파일을 읽어온다.\n",
    "data_df = pd.read_csv('data/ChatBotData.csv', header=0)\n",
    "question, answer = list(data_df['Q']), list(data_df['A'])\n",
    "\n",
    "# 특수 문자를 제거한다.\n",
    "FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "question = [re.sub(FILTERS, \"\", s) for s in question]\n",
    "answer = [re.sub(FILTERS, \"\", s) for s in answer]\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T23:42:10.565096Z",
     "start_time": "2022-12-25T23:42:10.544795Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "tNgnK1oGJaKg",
    "outputId": "2502e149-1656-4a04-de79-63c72098ce7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('성공할 수 있을까', '인내할 수 있는 사람이라면 무엇이든 손에 넣을 수 있을 거예요')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 학습 데이터와 시험 데이터를 분리한다.\n",
    "que_train, que_test, ans_train, ans_test = train_test_split(question, answer, test_size=0.1, random_state=0)\n",
    "\n",
    "que_train[0], ans_train[0]\n",
    "que_train[19], ans_train[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T23:42:18.118450Z",
     "start_time": "2022-12-25T23:42:17.719697Z"
    },
    "id": "Dt90Pze7JdwE"
   },
   "outputs": [],
   "source": [
    "# Sentencepice용 사전을 만들기 위해 que_train + que_test를 저장해 둔다.\n",
    "data_file = \"data/chatbot_data.txt\"\n",
    "with open(data_file, 'w', encoding='utf-8') as f:\n",
    "    for sent in question + answer:\n",
    "        f.write(sent + '\\n')\n",
    "        \n",
    "# Google의 Sentencepiece를 이용해서 vocabulary를 생성한다.\n",
    "# -----------------------------------------------------\n",
    "templates= \"--input={} \\\n",
    "            --pad_id=0 --pad_piece=<PAD>\\\n",
    "            --unk_id=1 --unk_piece=<UNK>\\\n",
    "            --bos_id=2 --bos_piece=<BOS>\\\n",
    "            --eos_id=3 --eos_piece=<EOS>\\\n",
    "            --model_prefix={} \\\n",
    "            --vocab_size={}\"\n",
    "\n",
    "VOCAB_SIZE = 9000\n",
    "model_prefix = \"data/chatbot_model\"\n",
    "params = templates.format(data_file, model_prefix, VOCAB_SIZE)\n",
    "\n",
    "spm.SentencePieceTrainer.Train(params)\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(model_prefix + '.model')\n",
    "\n",
    "with open(model_prefix + '.vocab', encoding='utf-8') as f:\n",
    "    vocab = [doc.strip().split('\\t') for doc in f]\n",
    "\n",
    "word2idx = {k:v for v, [k, _] in enumerate(vocab)}\n",
    "idx2word = {v:k for v, [k, _] in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-25T23:43:58.144890Z",
     "start_time": "2022-12-25T23:43:58.136034Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "bIKZCvOiJ8o2",
    "outputId": "4468ea85-0698-4786-bc67-3818e0e5ffd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <PAD>\n",
      "1 <UNK>\n",
      "2 <BOS>\n",
      "3 <EOS>\n",
      "4 ▁\n",
      "5 을\n",
      "6 가\n",
      "7 도\n",
      "8 요\n",
      "9 이\n",
      "10 는\n",
      "11 게\n",
      "12 ▁거예요\n",
      "13 은\n",
      "14 세요\n"
     ]
    }
   ],
   "source": [
    "for i, (k, v) in enumerate(idx2word.items()):\n",
    "    if i == 15:\n",
    "        break\n",
    "    print(k, v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "EAGoG9WRHWUd"
   },
   "outputs": [],
   "source": [
    "# 학습 데이터를 생성한다. (인코더 입력용, 디코더 입력용, 디코더 출력용)\n",
    "MAX_LEN = 15    # subword 길이\n",
    "enc_input = []\n",
    "dec_input = []\n",
    "dec_output = []\n",
    "\n",
    "for Q, A in zip(question, answer):\n",
    "    # Encoder 입력\n",
    "    enc_i = sp.encode_as_ids(Q)\n",
    "    enc_input.append(enc_i)\n",
    "\n",
    "    # Decoder 입력, 출력\n",
    "    dec_i = [sp.bos_id()]   # <BOS>에서 시작함\n",
    "    dec_o = []\n",
    "    for ans in sp.encode_as_ids(A):\n",
    "        dec_i.append(ans)\n",
    "        dec_o.append(ans)\n",
    "    dec_o.append(sp.eos_id())   # Decoder 출력은 <EOS>로 끝남.        \n",
    "    \n",
    "    # dec_o는 <EOS>가 마지막에 들어있다. 나중에 pad_sequences()에서 <EOS>가\n",
    "    # 잘려 나가지 않도록 MAX_LEN 위치에 <EOS>를 넣어준다.\n",
    "    if len(dec_o) > MAX_LEN:\n",
    "        dec_o[MAX_LEN] = sp.eos_id()\n",
    "        \n",
    "    dec_input.append(dec_i)\n",
    "    dec_output.append(dec_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "W2rZzHTMUCiG"
   },
   "outputs": [],
   "source": [
    "# 각 문장의 길이를 맞추고 남는 부분에 padding을 삽입한다.\n",
    "enc_input = pad_sequences(enc_input, maxlen=MAX_LEN, value = sp.pad_id(), padding='post', truncating='post')\n",
    "dec_input = pad_sequences(dec_input, maxlen=MAX_LEN, value = sp.pad_id(), padding='post', truncating='post')\n",
    "dec_output = pad_sequences(dec_output, maxlen=MAX_LEN, value = sp.pad_id(), padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "_DxQCfaqUsDA",
    "outputId": "11492a84-de3b-4cd5-ca12-e4f1a58596a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1지망 학교 떨어졌어', '위로해 드립니다')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question[1], answer[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "M0rPQ5C6UGZk",
    "outputId": "a9cb771d-929e-4a0e-bebf-2e6d121984e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 251, 7084,  724, 1598,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Jp6jwabqUP72",
    "outputId": "1e2c9dc5-bccf-4c94-c18f-eb67d746781f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2, 1421,  143, 1465,   91,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "jwXJiuHmUSDC",
    "outputId": "fd38f2f3-d94b-4303-879f-3a061fc283a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1421,  143, 1465,   91,    3,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TP6ipDy4Jjsd"
   },
   "outputs": [],
   "source": [
    "# 사전과 학습 데이터를 저장한다.\n",
    "with open('data/chatbot_voc.pkl', 'wb') as f:\n",
    "    pickle.dump([word2idx, idx2word], f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# BLEU 평가를 위해 que_test와 ans_test를 저장해 둔다.\n",
    "with open('data/chatbot_train.pkl', 'wb') as f:\n",
    "    pickle.dump([enc_input, dec_input, dec_output], f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZpH0dZAMwnh"
   },
   "source": [
    "## Sequence to Sequence Model\n",
    "\n",
    "  - Sequence 형태의 입력을 하나의 벡터로 압축(context vector)후, sequence 형태의 출력을 만드는 모델\n",
    "  - 하나의 텍스트 문장이 입력으로 들어오면 하나의 텍스트 문장을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "o_itRUXAcu67"
   },
   "outputs": [],
   "source": [
    "# Seq2Seq 모델를 이용한 ChatBot : 학습 모듈 (Teacher forcing)\n",
    "#\n",
    "# 관련 논문 : Kyunghyun Cho, et. al., 2014,\n",
    "#             Learning Phrase Representations using RNN Encoder–Decoder \n",
    "#             for Statistical Machine Translation\n",
    "#\n",
    "# 저작자: 2021.05.26, 조성현 (blog.naver.com/chunjein)\n",
    "# copyright: SNS 등에 공개할 때는 출처에 저작자를 명시해 주시기 바랍니다.\n",
    "# -----------------------------------------------------------------------\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.layers import Embedding, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PGN7wA1GdhQK"
   },
   "outputs": [],
   "source": [
    "# Sub-word 사전 읽어온다.\n",
    "with open('data/chatbot_voc.pkl', 'rb') as f:\n",
    "    word2idx,  idx2word = pickle.load(f)\n",
    "\n",
    "# 학습 데이터 : 인코딩, 디코딩 입력, 디코딩 출력을 읽어온다.\n",
    "with open('data/chatbot_train.pkl', 'rb') as f:\n",
    "    trainXE, trainXD, trainYD = pickle.load(f)\n",
    "\t\n",
    "VOCAB_SIZE = len(idx2word)\n",
    "EMB_SIZE = 128\n",
    "LSTM_HIDDEN = 128\n",
    "MODEL_PATH = 'data/chatbot_trained.h5'\n",
    "LOAD_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "eStjUdHmd4N2",
    "outputId": "f5346e65-b645-40f2-cf6b-b881b9080b1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([259,   6, 100,  90,  36,   3,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainYD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "B7SXvOn2d5mT",
    "outputId": "cf6b80a1-2822-4612-cb74-d4dd1d90fbab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁하루', '가', '▁또', '▁가', '네요', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "print([idx2word[i] for i in trainYD[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "vMQwa9JgckGV",
    "outputId": "36623308-4a37-450a-d43c-773628972411"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 15)]         0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 15)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 15, 128)      1152000     ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 15, 128),    131584      ['embedding[0][0]']              \n",
      "                                 (None, 128),                                                     \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 15, 128),    131584      ['embedding[1][0]',              \n",
      "                                 (None, 128),                     'lstm[0][1]',                   \n",
      "                                 (None, 128)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 128),        131584      ['lstm[0][0]']                   \n",
      "                                 (None, 128),                                                     \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, 15, 128),    131584      ['lstm_2[0][0]',                 \n",
      "                                 (None, 128),                     'lstm_1[0][1]',                 \n",
      "                                 (None, 128)]                     'lstm_1[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 15, 9000)    1161000     ['lstm_3[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,839,336\n",
      "Trainable params: 2,839,336\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 워드 임베딩 레이어. Encoder와 decoder에서 공동으로 사용한다.\n",
    "K.clear_session()\n",
    "wordEmbedding = Embedding(input_dim=VOCAB_SIZE, output_dim=EMB_SIZE)\n",
    "\n",
    "# Encoder\n",
    "# -------\n",
    "# many-to-one으로 구성한다. 중간 출력은 필요 없고 decoder로 전달할 h와 c만\n",
    "# 필요하다. h와 c를 얻기 위해 return_state = True를 설정한다.\n",
    "encoderX = Input(batch_shape=(None, trainXE.shape[1]))\n",
    "encEMB = wordEmbedding(encoderX)\n",
    "encLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state = True)        # return_sequences: 중간출력을 2층으로 올려보내기 위해 필요\n",
    "encLSTM2 = LSTM(LSTM_HIDDEN, return_state = True)\n",
    "ey1, eh1, ec1 = encLSTM1(encEMB)    # LSTM 1층 \n",
    "_, eh2, ec2 = encLSTM2(ey1)       # LSTM 2층\n",
    "\n",
    "# Decoder\n",
    "# -------\n",
    "# many-to-many로 구성한다. target을 학습하기 위해서는 중간 출력이 필요하다.\n",
    "# 그리고 초기 h와 c는 encoder에서 출력한 값을 사용한다 (initial_state)\n",
    "# 최종 출력은 vocabulary의 인덱스인 one-hot 인코더이다.\n",
    "decoderX = Input(batch_shape=(None, trainXD.shape[1]))\n",
    "decEMB = wordEmbedding(decoderX)\n",
    "decLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
    "decLSTM2 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
    "dy1, _, _ = decLSTM1(decEMB, initial_state = [eh1, ec1])\n",
    "dy2, _, _ = decLSTM2(dy1, initial_state = [eh2, ec2])\n",
    "decOutput = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))\n",
    "outputY = decOutput(dy2)\n",
    "\n",
    "# Model\n",
    "# -----\n",
    "model = Model([encoderX, decoderX], outputY)\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.0005), \n",
    "              loss='sparse_categorical_crossentropy')\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    model.load_weights(MODEL_PATH)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "xzxOMAVDjzqk",
    "outputId": "70fd43e9-ca58-4200-da33-62ba67e9ae37"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-490ca54583c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 학습 결과를 저장한다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Loss history를 그린다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# 학습 (teacher forcing)\n",
    "# ----------------------\n",
    "hist = model.fit([trainXE, trainXD], trainYD, batch_size = 512, epochs=50, shuffle=True)\n",
    "\n",
    "# 학습 결과를 저장한다\n",
    "model.save_weights(MODEL_PATH)\n",
    "\n",
    "# Loss history를 그린다\n",
    "plt.plot(hist.history['loss'], label='Train loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss history\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLy-d8r82ECr"
   },
   "source": [
    "## Chat Bot model (Seq2Seq를 이용한 챗봇모델 구현)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "4BLtuniV2IDp",
    "outputId": "c11e86a2-fbc0-44c2-f1d6-c7e61ae8e8fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |▎                               | 10 kB 18.8 MB/s eta 0:00:01\r",
      "\u001b[K     |▌                               | 20 kB 14.5 MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 30 kB 10.6 MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 40 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▍                              | 51 kB 4.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 61 kB 5.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 71 kB 5.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 81 kB 4.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 92 kB 4.7 MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 102 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 112 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 122 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 133 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 143 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 153 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 163 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 174 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 184 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 194 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 204 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 215 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 225 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 235 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 245 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 256 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 266 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 276 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 286 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 296 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 307 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 317 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 327 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 337 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 348 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 358 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 368 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 378 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 389 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 399 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 409 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 419 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 430 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 440 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 450 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 460 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 471 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 481 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 491 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 501 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 512 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 522 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 532 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 542 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 552 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 563 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 573 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 583 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 593 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 604 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 614 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 624 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 634 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 645 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 655 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 665 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 675 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 686 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 696 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 706 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 716 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 727 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 737 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 747 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 757 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 768 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 778 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 788 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 798 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 808 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 819 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 829 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 839 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 849 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 860 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 870 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 880 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 890 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 901 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 911 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 921 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 931 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 942 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 952 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 962 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 972 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 983 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 993 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 1.0 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 1.0 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.0 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 1.0 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 1.0 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 1.1 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 1.2 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 1.2 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 1.2 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 1.2 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 1.2 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 1.2 MB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.2 MB 5.1 MB/s \n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.96\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "q_bmYv2q2L2-"
   },
   "outputs": [],
   "source": [
    "# Seq2Seq 모델를 이용한 ChatBot : 채팅 모듈\n",
    "#\n",
    "# 관련 논문 : Kyunghyun Cho, et. al., 2014,\n",
    "#            Learning Phrase Representations using RNN Encoder–Decoder \n",
    "#            for Statistical Machine Translation\n",
    "#\n",
    "# 저작자: 2021.05.26, 조성현 (blog.naver.com/chunjein)\n",
    "# copyright: SNS 등에 공개할 때는 출처에 저작자를 명시해 주시기 바랍니다.\n",
    "# ----------------------------------------------------------------------\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.layers import Embedding, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "import sentencepiece as spm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "EoH7ctLD2_Eb",
    "outputId": "042ce285-50b9-4998-a234-dad6fd57b710"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "# 작업 디렉토리를 변경한다.\n",
    "%cd '/content/drive/My Drive/Colab Notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-Zj3n8Gd29qh"
   },
   "outputs": [],
   "source": [
    "# Sub-word 사전 읽어온다.\n",
    "with open('data/chatbot_voc.pkl', 'rb') as f:\n",
    "    word2idx,  idx2word = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "91GOvans3Ap4",
    "outputId": "31d17545-0007-4060-bb24-8994162c9d9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(idx2word)\n",
    "EMB_SIZE = 128\n",
    "LSTM_HIDDEN = 128\n",
    "MAX_LEN = 15            # 단어 시퀀스 길이\n",
    "MODEL_PATH = 'data/chatbot_trained.h5'\n",
    "\n",
    "# 데이터 전처리 과정에서 생성한 SentencePiece model을 불러온다.\n",
    "SPM_MODEL = \"data/chatbot_model.model\"\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(SPM_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "78WynWRQ2FoU"
   },
   "outputs": [],
   "source": [
    "# 워드 임베딩 레이어. Encoder와 decoder에서 공동으로 사용한다.\n",
    "K.clear_session()\n",
    "wordEmbedding = Embedding(input_dim=VOCAB_SIZE, output_dim=EMB_SIZE)\n",
    "\n",
    "# Encoder\n",
    "# -------\n",
    "# c는 long term, short term(의 비중?)을 컨트롤 하는 cell state\n",
    "encoderX = Input(batch_shape=(None, MAX_LEN))\n",
    "encEMB = wordEmbedding(encoderX)\n",
    "encLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state = True)\n",
    "encLSTM2 = LSTM(LSTM_HIDDEN, return_state = True)\n",
    "ey1, eh1, ec1 = encLSTM1(encEMB)    # LSTM 1층 \n",
    "_, eh2, ec2 = encLSTM2(ey1)         # LSTM 2층\n",
    "\n",
    "# Decoder\n",
    "# -------\n",
    "# Decoder는 1개 단어씩을 입력으로 받는다. (앞과 이 부분이 다름)\n",
    "# chat bot 학습때는 teacher forcing.\n",
    "decoderX = Input(batch_shape=(None, 1))\n",
    "decEMB = wordEmbedding(decoderX)\n",
    "decLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
    "decLSTM2 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
    "dy1, _, _ = decLSTM1(decEMB, initial_state = [eh1, ec1])\n",
    "dy2, _, _ = decLSTM2(dy1, initial_state = [eh2, ec2])\n",
    "decOutput = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))\n",
    "outputY = decOutput(dy2)\n",
    "\n",
    "# Model\n",
    "# -----\n",
    "model = Model([encoderX, decoderX], outputY)\n",
    "model.load_weights(MODEL_PATH)\n",
    "\n",
    "\n",
    "\n",
    "# Chatting용 model\n",
    "model_enc = Model(encoderX, [eh1, ec1, eh2, ec2])\n",
    "\n",
    "ih1 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "ic1 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "ih2 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "ic2 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "\n",
    "dec_output1, dh1, dc1 = decLSTM1(decEMB, initial_state = [ih1, ic1])\n",
    "dec_output2, dh2, dc2 = decLSTM2(dec_output1, initial_state = [ih2, ic2])\n",
    "\n",
    "dec_output = decOutput(dec_output2)\n",
    "model_dec = Model([decoderX, ih1, ic1, ih2, ic2], [dec_output, dh1, dc1, dh2, dc2])\n",
    "\n",
    "# -----------\n",
    "# Question을 입력받아 Answer를 생성한다.\n",
    "def genAnswer(question):\n",
    "    question = question[np.newaxis, :]\n",
    "    init_h1, init_c1, init_h2, init_c2 = model_enc.predict(question)\n",
    "\n",
    "    # 시작 단어는 <BOS>로 한다.\n",
    "    word = np.array(sp.bos_id()).reshape(1, 1)\n",
    "\n",
    "    answer = []\n",
    "    for i in range(MAX_LEN):\n",
    "        dY, next_h1, next_c1, next_h2, next_c2 = model_dec.predict([word, init_h1, init_c1, init_h2, init_c2])\n",
    "        \n",
    "        # 디코더의 출력은 vocabulary에 대응되는 one-hot이다.\n",
    "        # argmax로 해당 단어를 채택한다.\n",
    "        print(dY.shape)     # (1, 1, 9000) => len(word2idx) = 9000\n",
    "        print(dY)\n",
    "        random_pick = random.randrange(len(dY[0, 0]))\n",
    "        \n",
    "        # nextWord = np.argmax(dY[0, 0])\n",
    "        nextWord = random_pick\n",
    "\n",
    "        # 예상 단어가 <EOS>이거나 <PAD>이면 더 이상 예상할 게 없다.\n",
    "        if nextWord == sp.eos_id() or nextWord == sp.pad_id():\n",
    "            break\n",
    "        \n",
    "        # 다음 예상 단어인 디코더의 출력을 answer에 추가한다.\n",
    "        answer.append(idx2word[nextWord])\n",
    "        \n",
    "        # 디코더의 다음 recurrent를 위해 입력 데이터와 hidden 값을\n",
    "        # 준비한다. 입력은 word이고, hidden은 h와 c이다.\n",
    "        word = np.array(nextWord).reshape(1,1)\n",
    "    \n",
    "        init_h1 = next_h1\n",
    "        init_c1 = next_c1\n",
    "        init_h2 = next_h2\n",
    "        init_c2 = next_c2\n",
    "        \n",
    "    return sp.decode_pieces(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_kmcFWFT8Cys"
   },
   "outputs": [],
   "source": [
    "def make_question(que_string):\n",
    "    q_idx = []\n",
    "    for x in sp.encode_as_pieces(que_string):\n",
    "        if x in word2idx:\n",
    "            q_idx.append(word2idx[x])\n",
    "        else:\n",
    "            q_idx.append(sp.unk_id())   # out-of-vocabulary (OOV)\n",
    "    \n",
    "    # <PAD>를 삽입한다.\n",
    "    if len(q_idx) < MAX_LEN:\n",
    "        q_idx.extend([sp.pad_id()] * (MAX_LEN - len(q_idx)))\n",
    "    else:\n",
    "        q_idx = q_idx[0:MAX_LEN]\n",
    "    return q_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "r0VcJcrZ8Csr"
   },
   "outputs": [],
   "source": [
    "# Chatting\n",
    "# dummy : 최초 1회는 모델을 로드하는데 약간의 시간이 걸리므로 이것을 가리기 위함.\n",
    "def chatting(n=100):\n",
    "    for i in range(n):\n",
    "        question = input('Q : ')\n",
    "        \n",
    "        if  question == 'quit':\n",
    "            break\n",
    "        \n",
    "        q_idx = make_question(question)\n",
    "        answer = genAnswer(np.array(q_idx))\n",
    "        print('A :', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ZzkVmNWn4IZv",
    "outputId": "6d50a340-e7c1-4d31-af42-d91b69bc1c3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seq2Seq ChatBot (ver. 1.0)\n",
      "Chatting 모듈을 로드하고 있습니다 ...\n",
      "(1, 1, 9000)\n",
      "[[[2.8888815e-07 9.3303330e-09 9.0820755e-09 ... 8.0014768e-09\n",
      "   6.0870402e-09 7.5507476e-09]]]\n",
      "(1, 1, 9000)\n",
      "[[[3.4904838e-07 5.6802403e-08 7.3648216e-09 ... 6.6628068e-09\n",
      "   6.8739134e-09 6.5793069e-09]]]\n",
      "(1, 1, 9000)\n",
      "[[[1.2962891e-05 7.2490889e-06 4.8924118e-08 ... 3.9227032e-08\n",
      "   4.0696484e-08 4.1159161e-08]]]\n",
      "(1, 1, 9000)\n",
      "[[[3.1682546e-04 1.6736411e-05 6.2273536e-08 ... 4.6575384e-08\n",
      "   5.1000150e-08 5.4509911e-08]]]\n",
      "(1, 1, 9000)\n",
      "[[[4.2448264e-05 2.3891438e-12 8.0371239e-09 ... 5.8274305e-09\n",
      "   6.3216961e-09 6.4201826e-09]]]\n",
      "(1, 1, 9000)\n",
      "[[[6.5838508e-06 7.2073528e-11 3.9609556e-09 ... 2.9595997e-09\n",
      "   3.3970957e-09 3.4606900e-09]]]\n",
      "(1, 1, 9000)\n",
      "[[[4.3749413e-08 4.0472833e-13 7.5987627e-10 ... 6.2952837e-10\n",
      "   6.4857714e-10 6.4174766e-10]]]\n",
      "(1, 1, 9000)\n",
      "[[[6.0472367e-08 1.1730505e-10 1.6637413e-09 ... 1.5241192e-09\n",
      "   1.6585041e-09 1.5470845e-09]]]\n",
      "(1, 1, 9000)\n",
      "[[[1.9577182e-04 2.0250167e-13 4.9714823e-09 ... 4.1488013e-09\n",
      "   3.9661145e-09 4.1476858e-09]]]\n",
      "(1, 1, 9000)\n",
      "[[[1.1192335e-05 7.2449987e-14 5.5082688e-10 ... 4.5595872e-10\n",
      "   4.5228277e-10 4.5379059e-10]]]\n",
      "(1, 1, 9000)\n",
      "[[[3.0372225e-05 4.7699268e-14 2.1129367e-09 ... 1.6505076e-09\n",
      "   1.6905476e-09 1.7014620e-09]]]\n",
      "(1, 1, 9000)\n",
      "[[[1.5085069e-05 1.2953125e-14 2.9522316e-09 ... 2.2726914e-09\n",
      "   2.3524360e-09 2.3477789e-09]]]\n",
      "(1, 1, 9000)\n",
      "[[[1.12468064e-04 4.64135987e-11 1.78657249e-08 ... 1.51940274e-08\n",
      "   1.56870161e-08 1.48725503e-08]]]\n",
      "(1, 1, 9000)\n",
      "[[[4.55542991e-04 1.34900812e-13 1.03693845e-08 ... 8.41457126e-09\n",
      "   9.01241126e-09 8.62384919e-09]]]\n",
      "(1, 1, 9000)\n",
      "[[[1.3441452e-05 7.4010927e-15 3.3347165e-09 ... 2.6507030e-09\n",
      "   2.8239362e-09 2.6822762e-09]]]\n",
      "ChatBot이 준비 됐습니다.\n",
      "Q : quit\n"
     ]
    }
   ],
   "source": [
    "####### Chatting 시작 #######\n",
    "print(\"\\nSeq2Seq ChatBot (ver. 1.0)\")\n",
    "print(\"Chatting 모듈을 로드하고 있습니다 ...\")\n",
    "\n",
    "# 처음 1회는 시간이 걸리기 때문에 dummy question을 입력한다.\n",
    "answer = genAnswer(np.zeros(MAX_LEN))\n",
    "print(\"ChatBot이 준비 됐습니다.\")\n",
    "\n",
    "# 채팅을 시작한다.\n",
    "chatting(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jIUFvd0y7iQ1"
   },
   "outputs": [],
   "source": [
    "# train data:\n",
    "#  ('허기져', '챙겨 드세요'),\n",
    "#  ('맥주 소주 어떤거 마실까', '소맥이요'),\n",
    "#  ('교양 수업 재밌어', '저도 듣고 싶어요'),\n",
    "#  ('권태기 이별', '극복하거나 이별하거나 둘 중 하나죠'),\n",
    "#  ('읽씹은 아프네', '상대방에 대한 예의가 없네요'),\n",
    "#  ('신혼여행 어디로 갈까', '못 가본 곳으로 가보세요'),\n",
    "#  ('반 배정 잘 될까', '잘 되길 바랍니다'),\n",
    "#  ('친구가 다 떠나서 내가 못났나 싶어', '지난 인연에 연연해하지 마세요'),\n",
    "#  ('뒤돌아 보지 말고 나가야 하는데', '살짝 뒤돌아봐도 괜찮아요')\n",
    "#  ('소오름 쫙', '좋은 일이길 바랍니다'),\n",
    "#  ('고백은 어떻게 하는거야', '솔직한 마음으로 다가가는 거죠'),\n",
    "#  ('참 잘낫네', '진정하셔요'),\n",
    "#  ('늘 빡빡하게 살기 힘드네', '여유가 생기길 바랍니다'),\n",
    "#  ('집까지 데려다줬는데 호감 그냥 매너', '호감이 있을 수도 있어요 그렇지만 조금 더 상황을 지켜보세요'),\n",
    "#  ('짝녀가 연락 안 되고 있는데 자나', '자고 있을지도 모르겠어요'),\n",
    "#  ('마음도 춥고 날씨도 춥고', '마음 감기 조심하세요'),\n",
    "#  ('죽었던 연애세포가 살아나는 것 같아', '좋은 소식이네요'),\n",
    "#  ('겨울에는 온천이지', '몸은 뜨겁고 머리는 차갑게'),\n",
    "#  ('소개팅 하고싶다', '친구한테 부탁해보세요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ygZalhsfApKi",
    "outputId": "65b61894-2879-4b29-d2f8-bdeb9ec91d6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88079708, 0.11920292])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = 0.3\n",
    "a = np.array([0.8, 0.2])\n",
    "np.exp(a/beta) / np.sum(np.exp(a/beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qeEvBIT1o3Ul"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0wi1FctuVo1"
   },
   "source": [
    "# beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2jmuhAwuWMC"
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece\n",
    "\n",
    "# Seq2Seq 모델를 이용한 ChatBot : 채팅 모듈\n",
    "#\n",
    "# 관련 논문 : Kyunghyun Cho, et. al., 2014,\n",
    "#            Learning Phrase Representations using RNN Encoder–Decoder \n",
    "#            for Statistical Machine Translation\n",
    "#\n",
    "# 저작자: 2021.05.26, 조성현 (blog.naver.com/chunjein)\n",
    "# copyright: SNS 등에 공개할 때는 출처에 저작자를 명시해 주시기 바랍니다.\n",
    "# ----------------------------------------------------------------------\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.layers import Embedding, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "import sentencepiece as spm\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "# 작업 디렉토리를 변경한다.\n",
    "# %cd '/content/drive/My Drive/Colab Notebooks'\n",
    "\n",
    "# Sub-word 사전 읽어온다.\n",
    "with open('data/chatbot_voc.pkl', 'rb') as f:\n",
    "    word2idx,  idx2word = pickle.load(f)\n",
    "\n",
    "VOCAB_SIZE = len(idx2word)\n",
    "EMB_SIZE = 128\n",
    "LSTM_HIDDEN = 128\n",
    "MAX_LEN = 15            # 단어 시퀀스 길이\n",
    "MODEL_PATH = 'data/chatbot_trained.h5'\n",
    "SOFT_BETA = 1.0\n",
    "\n",
    "# 데이터 전처리 과정에서 생성한 SentencePiece model을 불러온다.\n",
    "SPM_MODEL = \"data/chatbot_model.model\"\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(SPM_MODEL)\n",
    "\n",
    "# 워드 임베딩 레이어. Encoder와 decoder에서 공동으로 사용한다.\n",
    "K.clear_session()\n",
    "wordEmbedding = Embedding(input_dim=VOCAB_SIZE, output_dim=EMB_SIZE)\n",
    "\n",
    "# Encoder\n",
    "# -------\n",
    "encoderX = Input(batch_shape=(None, MAX_LEN))\n",
    "encEMB = wordEmbedding(encoderX)\n",
    "encLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state = True)\n",
    "encLSTM2 = LSTM(LSTM_HIDDEN, return_state = True)\n",
    "ey1, eh1, ec1 = encLSTM1(encEMB)    # LSTM 1층 \n",
    "_, eh2, ec2 = encLSTM2(ey1)         # LSTM 2층\n",
    "\n",
    "# Decoder\n",
    "# -------\n",
    "decoderX = Input(batch_shape=(None, 1))\n",
    "decEMB = wordEmbedding(decoderX)\n",
    "decLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
    "decLSTM2 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
    "dy1, _, _ = decLSTM1(decEMB, initial_state = [eh1, ec1])\n",
    "dy2, _, _ = decLSTM2(dy1, initial_state = [eh2, ec2])\n",
    "decOutput = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))\n",
    "outputY = decOutput(dy2)\n",
    "\n",
    "model = Model([encoderX, decoderX], outputY)\n",
    "model.load_weights(MODEL_PATH)\n",
    "\n",
    "# Chatting model\n",
    "# --------------\n",
    "model_enc = Model(encoderX, [eh1, ec1, eh2, ec2])\n",
    "\n",
    "ih1 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "ic1 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "ih2 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "ic2 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
    "\n",
    "dec_output1, dh1, dc1 = decLSTM1(decEMB, initial_state = [ih1, ic1])\n",
    "dec_output2, dh2, dc2 = decLSTM2(dec_output1, initial_state = [ih2, ic2])\n",
    "\n",
    "dec_output = decOutput(dec_output2)\n",
    "model_dec = Model([decoderX, ih1, ic1, ih2, ic2], [dec_output, dh1, dc1, dh2, dc2])\n",
    "\n",
    "\n",
    "# 컴퓨터가 실숫값을 할당할때 8byte(double precision), 4byte(single precision) 할당이 있는데 8*8 = 64bit, 8*4 = 32bit 로 실숫값표시 => 정확도 차이가 있음\n",
    "# 4byte가 빨라서 GPU연산 내부적으로나 Keras, tensorflow 들은 주로 기본32bit 사용\n",
    "def rand_argmax(p, beta=1.2):\n",
    "    # 조절 변수인 beta를 사용해서 기존 softmax 확률값을 변형 시킨다.\n",
    "    p = np.asarray(p).astype('float64')\n",
    "    p = np.log(p + 1e-12) / beta\n",
    "\n",
    "    # new softmax\n",
    "    e = np.exp(p)\n",
    "    s = e / np.sum(e)\n",
    "\n",
    "    # new softmax 확률에 따라 단어 한 개를 선택한다.\n",
    "    probs = np.random.multinomial(1, s, 1)\n",
    "\n",
    "    return np.argmax(probs)\n",
    "\n",
    "# Question을 입력받아 Answer를 생성한다.\n",
    "def genAnswer(question):\n",
    "    question = question[np.newaxis, :]\n",
    "    init_h1, init_c1, init_h2, init_c2 = model_enc.predict(question)\n",
    "\n",
    "    # 시작 단어는 <BOS>로 한다.\n",
    "    word = np.array(sp.bos_id()).reshape(1, 1)\n",
    "\n",
    "    answer = []\n",
    "    for i in range(MAX_LEN):\n",
    "        dY, next_h1, next_c1, next_h2, next_c2 = model_dec.predict([word, init_h1, init_c1, init_h2, init_c2])\n",
    "        \n",
    "        # 디코더의 출력은 vocabulary에 대응되는 one-hot이다.\n",
    "        # nextWord = np.argmax(dY[0, 0])\n",
    "        nextWord = rand_argmax(dY[0, 0])\n",
    "\n",
    "        # 예상 단어가 <EOS>이거나 <PAD>이면 더 이상 예상할 게 없다.\n",
    "        if nextWord == sp.eos_id() or nextWord == sp.pad_id():\n",
    "            break\n",
    "        \n",
    "        # 다음 예상 단어인 디코더의 출력을 answer에 추가한다.\n",
    "        answer.append(idx2word[nextWord])\n",
    "        \n",
    "        # 디코더의 다음 recurrent를 위해 입력 데이터와 hidden 값을\n",
    "        word = np.array(nextWord).reshape(1,1)\n",
    "    \n",
    "        init_h1 = next_h1\n",
    "        init_c1 = next_c1\n",
    "        init_h2 = next_h2\n",
    "        init_c2 = next_c2\n",
    "        \n",
    "    return sp.decode_pieces(answer)\n",
    "\n",
    "def make_question(que_string):\n",
    "    q_idx = []\n",
    "    for x in sp.encode_as_pieces(que_string):\n",
    "        if x in word2idx:\n",
    "            q_idx.append(word2idx[x])\n",
    "        else:\n",
    "            q_idx.append(sp.unk_id())   # out-of-vocabulary (OOV)\n",
    "    \n",
    "    # <PAD>를 삽입한다.\n",
    "    if len(q_idx) < MAX_LEN:\n",
    "        q_idx.extend([sp.pad_id()] * (MAX_LEN - len(q_idx)))\n",
    "    else:\n",
    "        q_idx = q_idx[0:MAX_LEN]\n",
    "    return q_idx\n",
    "\n",
    "# Chatting\n",
    "# dummy : 최초 1회는 모델을 로드하는데 약간의 시간이 걸리므로 이것을 가리기 위함.\n",
    "def chatting(n=100):\n",
    "    for i in range(n):\n",
    "        question = input('Q : ')\n",
    "        \n",
    "        if  question == 'quit':\n",
    "            break\n",
    "        \n",
    "        q_idx = make_question(question)\n",
    "        answer = genAnswer(np.array(q_idx))\n",
    "        print('A :', answer)\n",
    "\n",
    "####### Chatting 시작 #######\n",
    "print(\"\\nSeq2Seq ChatBot (ver. 1.0)\")\n",
    "print(\"Chatting 모듈을 로드하고 있습니다 ...\")\n",
    "\n",
    "# 처음 1회는 시간이 걸리기 때문에 dummy question을 입력한다.\n",
    "answer = genAnswer(np.zeros(MAX_LEN))\n",
    "print(\"ChatBot이 준비 됐습니다.\")\n",
    "\n",
    "# 채팅을 시작한다.\n",
    "chatting(100)\n",
    "\n",
    "# train data:\n",
    "#  ('허기져', '챙겨 드세요'),\n",
    "#  ('맥주 소주 어떤거 마실까', '소맥이요'),\n",
    "#  ('교양 수업 재밌어', '저도 듣고 싶어요'),\n",
    "#  ('권태기 이별', '극복하거나 이별하거나 둘 중 하나죠'),\n",
    "#  ('읽씹은 아프네', '상대방에 대한 예의가 없네요'),\n",
    "#  ('신혼여행 어디로 갈까', '못 가본 곳으로 가보세요'),\n",
    "#  ('반 배정 잘 될까', '잘 되길 바랍니다'),\n",
    "#  ('친구가 다 떠나서 내가 못났나 싶어', '지난 인연에 연연해하지 마세요'),\n",
    "#  ('뒤돌아 보지 말고 나가야 하는데', '살짝 뒤돌아봐도 괜찮아요')\n",
    "#  ('소오름 쫙', '좋은 일이길 바랍니다'),\n",
    "#  ('고백은 어떻게 하는거야', '솔직한 마음으로 다가가는 거죠'),\n",
    "#  ('참 잘낫네', '진정하셔요'),\n",
    "#  ('늘 빡빡하게 살기 힘드네', '여유가 생기길 바랍니다'),\n",
    "#  ('집까지 데려다줬는데 호감 그냥 매너', '호감이 있을 수도 있어요 그렇지만 조금 더 상황을 지켜보세요'),\n",
    "#  ('짝녀가 연락 안 되고 있는데 자나', '자고 있을지도 모르겠어요'),\n",
    "#  ('마음도 춥고 날씨도 춥고', '마음 감기 조심하세요'),\n",
    "#  ('죽었던 연애세포가 살아나는 것 같아', '좋은 소식이네요'),\n",
    "#  ('겨울에는 온천이지', '몸은 뜨겁고 머리는 차갑게'),\n",
    "#  ('소개팅 하고싶다', '친구한테 부탁해보세요')\n",
    "\n",
    "beta = 1.0\n",
    "a = np.array([0.6, 0.1, 0.1, 0.2])\n",
    "s = np.exp(a / beta) / np.sum(np.exp(a / beta))\n",
    "s\n",
    "\n",
    "for i in range(10):\n",
    "    print(np.argmax(np.random.binomial(1, s)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArDN6qOcu7-v"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "0329(챗봇).ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
