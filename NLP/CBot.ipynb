{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "223a0b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T13:49:58.893740Z",
     "start_time": "2023-02-05T13:49:58.886759Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "602f4b22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T13:44:19.118661Z",
     "start_time": "2023-02-05T13:44:19.046232Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenizer를 불러온다.\n",
    "save_path = './CBot'\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.load_from_file(save_path + '/CBot_vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6256418e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T13:49:43.741958Z",
     "start_time": "2023-02-05T13:49:40.794973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x19d6a05ce50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformer\n",
    "\n",
    "# Hyperparameter 정의\n",
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "MAX_LENGTH = 40\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "\n",
    "# 모델 정의 (학습한 모델과 같은 구조)\n",
    "model = transformer.transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "# 이미 학습시켜놓은 가중치를 로드한다.\n",
    "model.load_weights(save_path + '/CBot_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae6dfeae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T13:49:43.788393Z",
     "start_time": "2023-02-05T13:49:43.774928Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \"\"\"\n",
    "    입력문장을 전처리하는 함수\n",
    "    \n",
    "    단어와 구두점 사이에 공백 추가.\n",
    "    ex) 12시 땡! -> 12시 땡 !\n",
    "    \"\"\"\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb9ff686",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T13:49:43.894747Z",
     "start_time": "2023-02-05T13:49:43.885037Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    # 입력 문장 전처리\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 입력 문장에 시작 토큰과 종료 토큰을 추가\n",
    "    sentence = tf.expand_dims(START_TKN + tokenizer.encode(sentence) + END_TKN, axis=0)\n",
    "    output = tf.expand_dims(START_TKN, 0)\n",
    "\n",
    "    # 디코더의 예측 시작\n",
    "    for i in range(MAX_LENGTH):\n",
    "        predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "        # 현재 시점의 예측 단어를 받아온다.\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "        if tf.equal(predicted_id, END_TKN[0]):\n",
    "            break\n",
    "\n",
    "        # 현재 시점의 예측 단어를 output(출력)에 연결한다.\n",
    "        # output은 for문의 다음 루프에서 디코더의 입력이 된다.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    # 단어 예측이 모두 끝났다면 output을 리턴.\n",
    "    return tf.squeeze(output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87b8811a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T13:50:04.768271Z",
     "start_time": "2023-02-05T13:50:02.607911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단순 채팅봇 CBot입니다.\n",
      "End, Exit 입력시 채팅봇이 종료됩니다.\n",
      "\n",
      "User: 안녕하세요\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'START_TKN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Answer\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m answer \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode([i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m prediction \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mvocab_size])\n\u001b[0;32m     19\u001b[0m answer \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ([?.!,])\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m, answer)    \u001b[38;5;66;03m# 특수문자 전 후 공백 제거\u001b[39;00m\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      3\u001b[0m sentence \u001b[38;5;241m=\u001b[39m preprocess_sentence(sentence)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 입력 문장에 시작 토큰과 종료 토큰을 추가\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m sentence \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(\u001b[43mSTART_TKN\u001b[49m \u001b[38;5;241m+\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(sentence) \u001b[38;5;241m+\u001b[39m END_TKN, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      7\u001b[0m output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(START_TKN, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 디코더의 예측 시작\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'START_TKN' is not defined"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "# t = time.time()\n",
    "print('단순 채팅봇 CBot입니다.')\n",
    "print('End, Exit 입력시 채팅봇이 종료됩니다.')\n",
    "print()\n",
    "\n",
    "while True:\n",
    "    # Input\n",
    "    sentence = input('User: ')\n",
    "    \n",
    "    # End, Exit => end the program\n",
    "    end_words = ['END', 'EXIT', '종료', '끝']\n",
    "    if sentence.upper() in end_words:\n",
    "        break\n",
    "    \n",
    "    # Answer\n",
    "    prediction = evaluate(sentence)\n",
    "    answer = tokenizer.decode([i for i in prediction if i < tokenizer.vocab_size])\n",
    "    answer = re.sub(r\" ([?.!,])\", r\"\\1\", answer)    # 특수문자 전 후 공백 제거\n",
    "    print(f\"CBot: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ab558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
