{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ed4d9a",
   "metadata": {},
   "source": [
    "## Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab755fae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T17:10:48.565977Z",
     "start_time": "2022-11-21T17:10:47.268338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "학습데이터의 정확도 = 0.99\n",
      "시험데이터의 정확도 = 1.00\n",
      "\n",
      "Confusion matrix :\n",
      "[[12  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0  4]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        12\n",
      "  versicolor       1.00      1.00      1.00        14\n",
      "   virginica       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Majority voting의 앙상블 방법을 연습한다.\n",
    "# ----------------------------------------\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# iris 데이터를 읽어온다.\n",
    "iris = load_iris()\n",
    "\n",
    "# Train 데이터 세트와 Test 데이터 세트를 구성한다\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris['data'], iris['target'], test_size = 0.2)\n",
    "\n",
    "# 4가지 모델을 생성한다 (KNN, Decision tree, SVM, Logistic Regression).\n",
    "# 각 모델은 최적 조건으로 생성한다. (knn의 k개수, dtree의 max_depth 등)\n",
    "# sklearn 문서 : Recommended for an ensemble of well-calibrated classifiers.\n",
    "knn = KNeighborsClassifier(n_neighbors=5, p=2)\n",
    "dtree = DecisionTreeClassifier(criterion='gini', max_depth=8)\n",
    "svm = SVC(kernel='rbf', gamma=0.1, C=1.0, probability=True)\n",
    "lreg = LogisticRegression(max_iter=500)\n",
    "\n",
    "# 4가지 모델로 앙상블을 구성한다.\n",
    "base_model = [('knn', knn), ('dtree', dtree), ('svm', svm), ('lr', lreg)]\n",
    "ensemble = VotingClassifier(estimators=base_model, voting='soft')\n",
    "\n",
    "ensemble\n",
    "\n",
    "# 4가지 모델을 각각 학습하고, 결과를 종합한다.\n",
    "# VotingClassifier()의 voting = ('hard' or 'soft')에 따라 아래와 같이 종합한다.\n",
    "# hard (default) : 4가지 모델에서 추정한 class = (0, 1, 2)중 가장 많은 것으로 판정.\n",
    "# soft : 4가지 모델에서 추정한 각 class의 확률값의 평균 (혹은 합)을 계산한 후,\n",
    "#        확률이 가장 높은 (argmax(P)) class로 판정한다.\n",
    "ensemble.fit(x_train, y_train)\n",
    "\n",
    "# 학습데이터와 시험데이터의 정확도를 측정한다.\n",
    "print('\\n학습데이터의 정확도 = %.2f' % ensemble.score(x_train, y_train))\n",
    "print('시험데이터의 정확도 = %.2f' % ensemble.score(x_test, y_test))\n",
    "\n",
    "# 시험데이터의 confusion matrix를 작성하고, (row : actual, col : predict),\n",
    "# 4개 score를 확인한다.\n",
    "y_pred = ensemble.predict(x_test)\n",
    "print('\\nConfusion matrix :')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951bbafb",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d8b76d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T17:10:51.366751Z",
     "start_time": "2022-11-21T17:10:48.598011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix :\n",
      "[[ 7  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 13]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         7\n",
      "  versicolor       1.00      0.90      0.95        10\n",
      "   virginica       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.98      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bagging에 의한 앙상블 방법을 연습한다.\n",
    "# ------------------------------------\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# iris 데이터를 읽어온다.\n",
    "iris = load_iris()\n",
    "\n",
    "# Train 데이터 세트와 Test 데이터 세트를 구성한다\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris['data'], iris['target'], test_size = 0.2)\n",
    "\n",
    "# 4가지 모델을 생성한다 (KNN, Decision tree, SVM, Logistic Regression).\n",
    "knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "dtree = DecisionTreeClassifier(criterion='gini', max_depth=8)\n",
    "svm = SVC(kernel='rbf', gamma=0.1, C=1.0, probability=True)\n",
    "lreg = LogisticRegression(max_iter=500)\n",
    "\n",
    "# 4가지 모델로 Bagging을 구성하고, 각 모델의 추정 확률을 누적한다.\n",
    "prob = np.zeros((y_test.shape[0], iris.target_names.shape[0]))\n",
    "base_model = [knn, dtree, svm, lreg]\n",
    "for m in base_model:\n",
    "    bag = BaggingClassifier(base_estimator=m, n_estimators=100)\n",
    "    bag.fit(x_train, y_train)\n",
    "    \n",
    "    prob += bag.predict_proba(x_test)\n",
    "\n",
    "# 확률의 누적합이 가장 큰 class를 찾고, 정확도를 측정한다.\n",
    "y_pred = np.argmax(prob, axis=1)\n",
    "\n",
    "# 시험데이터의 confusion matrix를 작성한다 (row : actual, col : predict)\n",
    "print('\\nConfusion matrix :')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89adb00f",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c45b25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T17:10:51.553716Z",
     "start_time": "2022-11-21T17:10:51.398045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix :\n",
      "[[ 9  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  0  9]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         9\n",
      "  versicolor       1.00      0.92      0.96        12\n",
      "   virginica       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForest에 의한 앙상블 방법을 연습한다.\n",
    "# ------------------------------------------\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# iris 데이터를 읽어온다.\n",
    "iris = load_iris()\n",
    "\n",
    "# Train 데이터 세트와 Test 데이터 세트를 구성한다\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris['data'], iris['target'], test_size = 0.2)\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=3, n_estimators=100)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# 시험데이터의 confusion matrix를 작성하고, (row : actual, col : predict),\n",
    "# 4개 score를 확인한다.\n",
    "y_pred = rf.predict(x_test)\n",
    "\n",
    "print('\\nConfusion matrix :')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fe9461",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4703a9b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T17:10:52.211483Z",
     "start_time": "2022-11-21T17:10:51.585155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix :\n",
      "[[11  0  0]\n",
      " [ 0 10  1]\n",
      " [ 0  0  8]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        11\n",
      "  versicolor       1.00      0.91      0.95        11\n",
      "   virginica       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.96      0.97      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost에 의한 앙상블 방법을 연습한다.\n",
    "# --------------------------------------\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# iris 데이터를 읽어온다.\n",
    "iris = load_iris()\n",
    "\n",
    "# Train 데이터 세트와 Test 데이터 세트를 구성한다\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris['data'], iris['target'], test_size = 0.2)\n",
    "\n",
    "svm = SVC(kernel='rbf', gamma=0.1, C=1.0, probability=True)\n",
    "aboost = AdaBoostClassifier(base_estimator=svm, n_estimators=100)\n",
    "aboost.fit(x_train, y_train)\n",
    "\n",
    "# 시험데이터의 confusion matrix를 작성하고, (row : actual, col : predict),\n",
    "# 4개 score를 확인한다.\n",
    "y_pred = aboost.predict(x_test)\n",
    "\n",
    "print('\\nConfusion matrix :')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
